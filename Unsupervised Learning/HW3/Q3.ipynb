{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdc6f555f0844ff8d2d98805f570f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b524ac59a544052b95f4526cbcaa038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03667c11ee640fa8eaa912499c99ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d3f0df26354e54ad099e0e638c6831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "length of the training set: 60000\n",
      "length of the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision   \n",
    "import torchvision.datasets as datasets \n",
    "device = 'mps' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# downloading mnist\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))   \n",
    "])\n",
    "mnist_trainset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "mnist_testset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "## printing lengths\n",
    "\n",
    "print('length of the training set: {}'.format(len(mnist_trainset)))\n",
    "print('length of the test set: {}'.format(len(mnist_testset)))\n",
    "\n",
    "## rendering a few example from each label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing labeld training x and y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 5277.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 4774.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing unlabled training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 59800/59800 [00:11<00:00, 5277.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing labeld test x and y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5428.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5363.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reformatting shape...\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "partition_index = 200  \n",
    "\n",
    "def one_hot(y):\n",
    "  #For converting a numpy array of 0-9 into a one hot encoding of vectors of length 10 \n",
    "  b = np.zeros((y.size, y.max() + 1))\n",
    "  b[np.arange(y.size), y] = 1\n",
    "  return b\n",
    "\n",
    "print('processing labeld training x and y')\n",
    "train_x = np.asarray([np.asarray(mnist_trainset[i][0]) for i in tqdm(range(partition_index))])\n",
    "train_y = one_hot(np.asarray([np.asarray(mnist_trainset[i][1]) for i in tqdm(range(partition_index))]))\n",
    "\n",
    "print('processing unlabled training data')\n",
    "train_unlabled = np.asarray([np.asarray(mnist_trainset[i][0]) for i in tqdm(range(200,len(mnist_trainset)))])\n",
    "\n",
    "print('processing labeld test x and y')\n",
    "test_x = np.asarray([np.asarray(mnist_testset[i][0]) for i in tqdm(range(len(mnist_testset)))])\n",
    "test_y = one_hot(np.asarray([np.asarray(mnist_testset[i][1]) for i in tqdm(range(len(mnist_testset)))]))\n",
    "\n",
    "print('reformatting shape...')\n",
    "#train_x = np.expand_dims(train_x, 1)\n",
    "#train_unlabled = np.expand_dims(train_unlabled, 1)\n",
    "#test_x = np.expand_dims(test_x, 1)\n",
    "\n",
    "#converting data to pytorch type\n",
    "torch_train_x = torch.tensor(train_x.astype(np.float32), requires_grad=True).to(device)\n",
    "torch_train_y = torch.tensor(train_y.astype(np.float32)).to(device)\n",
    "torch_test_x = torch.tensor(test_x.astype(np.float32), requires_grad=True).to(device)\n",
    "torch_test_y = torch.tensor(test_y.astype(np.float32)).to(device)\n",
    "torch_train_unlabled = torch.tensor(train_unlabled.astype(np.float32), requires_grad=True).to(device)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (backbone): Backbone(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (head): Head(\n",
       "    (fc1): Linear(in_features=288, out_features=16, bias=True)\n",
       "    (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16,16,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(16,32,3,padding=1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "#defining model head\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, n_class=10):\n",
    "        super(Head, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*3*3, 16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32, n_class)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = Backbone() \n",
    "        self.head = Head()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model_baseline = Model()\n",
    "print(model_baseline(torch_train_x[:1]).shape)\n",
    "model_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train without unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [41:25<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 547x209475 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\IPython\\core\\formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    340\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backend_bases.py:2362\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2359\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2361\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2362\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2363\u001b[0m             filename,\n\u001b[0;32m   2364\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2365\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2366\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2367\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2368\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2369\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backend_bases.py:2228\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2224\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2227\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2228\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:394\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:384\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\n\u001b[0;32m    385\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:411\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[1;34m(self, cleared)\u001b[0m\n\u001b[0;32m    409\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cleared:\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:84\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[1;34m(self, width, height, dpi)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[1;31mValueError\u001b[0m: Image size of 547x209475 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 74\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(maxacc))\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m maxacc\n\u001b[1;32m---> 74\u001b[0m supervised_maxacc \u001b[38;5;241m=\u001b[39m \u001b[43msupervised_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_baseline\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 69\u001b[0m, in \u001b[0;36msupervised_train\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 69\u001b[0m maxacc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_accuracy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# maximum value of accuracy\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(maxacc))\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maxacc\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def supervised_train(model):\n",
    "\n",
    "    batch_size = 32\n",
    "    lr = 0.01\n",
    "    momentum = 0.9 # set to 0.9 or 0.95\n",
    "    num_epochs = 2000 # a value more than 2000\n",
    "\n",
    "    #defining a stocastic gradient descent optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    #defining loss function\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_hist = []\n",
    "    test_hist = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "        #iterating over all batches\n",
    "        for i in range(int(len(train_x)/batch_size)-1):\n",
    "\n",
    "            #Put the model in training mode, so that things like dropout work\n",
    "            model.train(True) \n",
    "\n",
    "            # Zero gradients for the optimizer \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #extracting X and y values from the batch\n",
    "            X = torch_train_x[i*batch_size: (i+1)*batch_size]\n",
    "            y = torch_train_y[i*batch_size: (i+1)*batch_size]\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            y_pred = model(X)\n",
    "\n",
    "            #compute gradients with the loss function\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            #Disable things like dropout, if they exist\n",
    "            model.train(False)\n",
    "\n",
    "            #calculating epoch training and test loss\n",
    "            train_loss = loss_fn(model(torch_train_x), torch_train_y).cpu().numpy()\n",
    "            y_pred_test = model(torch_test_x)\n",
    "            test_loss = loss_fn(y_pred_test, torch_test_y).cpu().numpy()\n",
    "\n",
    "            train_hist.append(train_loss) # use train loss to plot\n",
    "            test_hist.append(test_loss) # use test loss to plot\n",
    "\n",
    "            #computing test accuracy\n",
    "            matches = np.equal(np.argmax(y_pred_test.cpu().numpy(), axis=1), np.argmax(torch_test_y.cpu().numpy(), axis=1))\n",
    "            test_accuracy.append(matches)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_hist, label = 'train loss')\n",
    "    plt.plot(test_hist, label = 'test loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.plot(test_accuracy, label = 'test accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    maxacc = max(test_accuracy)# maximum value of accuracy\n",
    "    print('max accuracy: {}'.format(maxacc))\n",
    "    \n",
    "    return maxacc\n",
    "\n",
    "supervised_maxacc = supervised_train(model_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mGenerating Test Augmentation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m a \u001b[38;5;241m=\u001b[39m Augment()\n\u001b[1;32m---> 27\u001b[0m aug \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_train_unlabled\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m f, axarr \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 21\u001b[0m, in \u001b[0;36mAugment.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_transform(x)\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:812\u001b[0m, in \u001b[0;36mRandomPerspective.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:\n\u001b[0;32m    811\u001b[0m     startpoints, endpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(width, height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistortion_scale)\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperspective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:749\u001b[0m, in \u001b[0;36mperspective\u001b[1;34m(img, startpoints, endpoints, interpolation, fill)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m    747\u001b[0m     _log_api_usage_once(perspective)\n\u001b[1;32m--> 749\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_perspective_coeffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(interpolation, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    752\u001b[0m     interpolation \u001b[38;5;241m=\u001b[39m _interpolation_modes_from_int(interpolation)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:709\u001b[0m, in \u001b[0;36m_get_perspective_coeffs\u001b[1;34m(startpoints, endpoints)\u001b[0m\n\u001b[0;32m    706\u001b[0m     a_matrix[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, p1[\u001b[38;5;241m0\u001b[39m], p1[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    708\u001b[0m b_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(startpoints, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolution\n\u001b[0;32m    711\u001b[0m output: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Augment:\n",
    "\n",
    "   def __init__(self):\n",
    "\n",
    "       blur = T.GaussianBlur(kernel_size=(3, 3))\n",
    "\n",
    "       self.train_transform = torch.nn.Sequential(\n",
    "           T.RandomAffine(degrees=15, translate=(0.1,0.1)),\n",
    "           T.RandomPerspective(distortion_scale=0.1, p=0.3),\n",
    "           T.RandomPerspective(distortion_scale=0.4, p=0.3),\n",
    "           T.RandomPerspective(0.2,0.5),\n",
    "           T.RandomApply([blur],p=0.5),\n",
    "           T.RandomApply([blur],p=0.7)\n",
    "       )\n",
    "\n",
    "   def __call__(self, x): \n",
    "       return self.train_transform(x), self.train_transform(x)\n",
    "\n",
    "\"\"\"\n",
    "Generating Test Augmentation\n",
    "\"\"\"\n",
    "a = Augment()\n",
    "aug = a(torch_train_unlabled[0:100])\n",
    "\n",
    "i=1\n",
    "f, axarr = plt.subplots(2,2)\n",
    "#positive pair\n",
    "axarr[0,0].imshow(aug[0].cpu().detach().numpy()[i,0])\n",
    "axarr[0,1].imshow(aug[1].cpu().detach().numpy()[i,0])\n",
    "#another positive pair\n",
    "axarr[1,0].imshow(aug[0].cpu().detach().numpy()[i+1,0])\n",
    "axarr[1,1].imshow(aug[1].cpu().detach().numpy()[i+1,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m        \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m ContrastiveLoss(\u001b[38;5;241m32\u001b[39m) \u001b[38;5;66;03m# use the above loss\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m fake_proj_0, fake_proj_1 \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_train_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m fake_proj_0 \u001b[38;5;241m=\u001b[39m fake_proj_0[:,\u001b[38;5;241m0\u001b[39m,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m fake_proj_1 \u001b[38;5;241m=\u001b[39m fake_proj_1[:,\u001b[38;5;241m0\u001b[39m,:,\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[42], line 21\u001b[0m, in \u001b[0;36mAugment.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_transform(x), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:812\u001b[0m, in \u001b[0;36mRandomPerspective.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:\n\u001b[0;32m    811\u001b[0m     startpoints, endpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(width, height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistortion_scale)\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperspective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:749\u001b[0m, in \u001b[0;36mperspective\u001b[1;34m(img, startpoints, endpoints, interpolation, fill)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m    747\u001b[0m     _log_api_usage_once(perspective)\n\u001b[1;32m--> 749\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_perspective_coeffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(interpolation, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    752\u001b[0m     interpolation \u001b[38;5;241m=\u001b[39m _interpolation_modes_from_int(interpolation)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:709\u001b[0m, in \u001b[0;36m_get_perspective_coeffs\u001b[1;34m(startpoints, endpoints)\u001b[0m\n\u001b[0;32m    706\u001b[0m     a_matrix[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, p1[\u001b[38;5;241m0\u001b[39m], p1[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    708\u001b[0m b_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(startpoints, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolution\n\u001b[0;32m    711\u001b[0m output: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."
     ]
    }
   ],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "   def __init__(self, batch_size, temperature=0.5):\n",
    "\n",
    "       super().__init__()\n",
    "       self.batch_size = batch_size\n",
    "       self.temperature = temperature\n",
    "       self.mask = (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float().to(device)\n",
    "\n",
    "   def calc_similarity_batch(self, a, b):\n",
    "       representations = torch.cat([a, b], dim=0)\n",
    "       return F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "\n",
    "   def forward(self, proj_1, proj_2):\n",
    "       batch_size = proj_1.shape[0]\n",
    "       z_i = F.normalize(proj_1, p=2, dim=1)\n",
    "       z_j = F.normalize(proj_2, p=2, dim=1)\n",
    "\n",
    "       similarity_matrix = self.calc_similarity_batch(z_i, z_j)\n",
    "\n",
    "       sim_ij = torch.diag(similarity_matrix, batch_size)\n",
    "       sim_ji = torch.diag(similarity_matrix, -batch_size)\n",
    "\n",
    "       positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "\n",
    "       nominator = torch.exp(positives / self.temperature)\n",
    "\n",
    "       denominator = self.mask * torch.exp(similarity_matrix / self.temperature)\n",
    "\n",
    "       all_losses = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
    "       loss = torch.sum(all_losses) / (2 * self.batch_size)\n",
    "       return loss\n",
    "\n",
    "loss = ContrastiveLoss(32) # use the above loss\n",
    "fake_proj_0, fake_proj_1 = a(torch_train_x)\n",
    "fake_proj_0 = fake_proj_0[:,0,:,0]\n",
    "fake_proj_1 = fake_proj_1[:,0,:,0]\n",
    "loss(fake_proj_0, fake_proj_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/116 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m X \u001b[38;5;241m=\u001b[39m torch_train_unlabled[j\u001b[38;5;241m*\u001b[39mbatch_size: (j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#creating pairs of augmented batches\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m X_aug_i, X_aug_j \u001b[38;5;241m=\u001b[39m \u001b[43maugmentfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#ensuring gradients are zero\u001b[39;00m\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[1;32mIn[42], line 21\u001b[0m, in \u001b[0;36mAugment.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_transform(x)\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:812\u001b[0m, in \u001b[0;36mRandomPerspective.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:\n\u001b[0;32m    811\u001b[0m     startpoints, endpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(width, height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistortion_scale)\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperspective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:749\u001b[0m, in \u001b[0;36mperspective\u001b[1;34m(img, startpoints, endpoints, interpolation, fill)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m    747\u001b[0m     _log_api_usage_once(perspective)\n\u001b[1;32m--> 749\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_perspective_coeffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(interpolation, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    752\u001b[0m     interpolation \u001b[38;5;241m=\u001b[39m _interpolation_modes_from_int(interpolation)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:709\u001b[0m, in \u001b[0;36m_get_perspective_coeffs\u001b[1;34m(startpoints, endpoints)\u001b[0m\n\u001b[0;32m    706\u001b[0m     a_matrix[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, p1[\u001b[38;5;241m0\u001b[39m], p1[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39mp2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m p1[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    708\u001b[0m b_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(startpoints, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolution\n\u001b[0;32m    711\u001b[0m output: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calling torch.linalg.lstsq on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "model = Model().to(device)\n",
    "model.train()\n",
    "\n",
    "#defining key hyperparameters\n",
    "batch_size = 512\n",
    "epoch_size = len(torch_train_unlabled) // batch_size\n",
    "num_epochs = 50# more than 50\n",
    "patience = 5\n",
    "cutoff_ratio = 0.001\n",
    "\n",
    "#defining key learning functions\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_examples = len(torch_train_unlabled)\n",
    "lossfn = ContrastiveLoss\n",
    "augmentfn = Augment()\n",
    "\n",
    "#for book keeping\n",
    "loss_hist = []\n",
    "improvement_hist = []\n",
    "schedule_hist = []\n",
    "\n",
    "#for exponentially decreasing learning rate\n",
    "scheduler = ExponentialLR(optimizer, gamma = 0.95)\n",
    "\n",
    "#for early stopping\n",
    "patience_count = 0\n",
    "\n",
    "#Training Loop\n",
    "avg_loss = 1e10\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    print('epoch {}/{}'.format(i,num_epochs))\n",
    "\n",
    "    total_loss = 0\n",
    "    loss_change = 0\n",
    "\n",
    "    for j in tqdm(range(epoch_size)):\n",
    "\n",
    "        #getting random batch\n",
    "        X = torch_train_unlabled[j*batch_size: (j+1)*batch_size]\n",
    "\n",
    "        #creating pairs of augmented batches\n",
    "        X_aug_i, X_aug_j = augmentfn(X)\n",
    "\n",
    "        #ensuring gradients are zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #passing through the model\n",
    "        z_i = model(X_aug_i)\n",
    "        z_j = model(X_aug_j)\n",
    "\n",
    "        #calculating loss on the model embeddings, and computing gradients\n",
    "        loss = lossfn(z_i, z_j)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if True:\n",
    "            z_i = model(X_aug_i)\n",
    "            z_j = model(X_aug_j)\n",
    "\n",
    "            #calculating new loss value\n",
    "            new_loss = lossfn(z_i, z_j)\n",
    "\n",
    "            loss_change += new_loss.cpu().detach().numpy() - loss.cpu().detach().numpy()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #step learning rate scheduler\n",
    "        schedule_hist.append(scheduler.get_last_lr())\n",
    "\n",
    "    #########################\n",
    "    # update scheduler here #\n",
    "    #########################\n",
    "    \n",
    "    #calculating percentage loss reduction\n",
    "    new_avg_loss = total_loss/epoch_size\n",
    "    per_loss_reduction = (avg_loss-new_avg_loss)/avg_loss\n",
    "    print('Percentage Loss Reduction: {}'.format(per_loss_reduction))\n",
    "\n",
    "    #deciding to stop if loss is not decreasing fast enough\n",
    "    if per_loss_reduction < cutoff_ratio:\n",
    "        patience_count+=1\n",
    "        print('patience counter: {}'.format(patience_count))\n",
    "        if patience_count > patience:\n",
    "            break\n",
    "    else:\n",
    "        patience_count = 0\n",
    "\n",
    "    #setting new loss as previous loss\n",
    "    avg_loss = new_avg_loss\n",
    "\n",
    "    #book keeping\n",
    "    avg_improvement = loss_change/epoch_size\n",
    "    loss_hist.append(avg_loss)\n",
    "    improvement_hist.append(avg_improvement)\n",
    "    print('Average Loss: {}'.format(avg_loss))\n",
    "    print('Average Loss change (if calculated): {}'.format(avg_improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjn0lEQVR4nO3de3CU1QH38d+Sy4ZoslICCdEAwVJIRGY0jCHpRGyLIbEg1LRF0VQdpcYbBuoIeCkMzhCgjqU2IDWitVMr1gKW6SAvWCqlZkGhgCmJ1Eu4KFm5iLupYK7n/YM3+7rmAoE8Sfbw/czsH3n2PJtzzqD58uTZxWWMMQIAALBIn56eAAAAQFcjcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYJ7KnJ9ATmpubdfjwYcXFxcnlcvX0dAAAwFkwxqi2tlbJycnq06fjazQXZOAcPnxYKSkpPT0NAABwDg4dOqTLLruswzEXZODExcVJOr1B8fHxPTwbAABwNgKBgFJSUoI/xztyQQZOy6+l4uPjCRwAAMLM2dxewk3GAADAOgQOAACwDoEDAACsc0HegwMAQHczxqixsVFNTU09PZVeLSoqShEREef9OgQOAAAOq6+vV01NjU6ePNnTU+n1XC6XLrvsMl188cXn9ToEDgAADmpublZ1dbUiIiKUnJys6OhoPmS2HcYYHT16VJ988omGDx9+XldyCBwAABxUX1+v5uZmpaSkKDY2tqen0+sNGDBA+/fvV0NDw3kFDjcZAwDQDc70TwvgtK66usVuAwAA6xA4AADAOgQOAABo5brrrlNxcXFPT+OcETgAAMA6BA4AALAOgQMAQDcyxuhkfWOPPIwx5zTnEydO6Gc/+5n69eun2NhY5efn64MPPgg+f+DAAU2aNEn9+vXTRRddpCuuuELr168PnnvrrbdqwIAB6tu3r4YPH64XX3yxS/ayI3wODgAA3ehUQ5PSf/l/euR7Vy6YoNjozv/ov+OOO/TBBx9o3bp1io+P1+zZs3XDDTeosrJSUVFRuv/++1VfX69//vOfuuiii1RZWRn8JOInnnhClZWVeuONN5SQkKAPP/xQp06d6uqltULgAACAdrWEzdtvv63s7GxJ0ssvv6yUlBS9/vrr+slPfqKDBw+qoKBAV155pSRp2LBhwfMPHjyoq666SmPGjJEkDR06tFvmTeAAANCN+kZFqHLBhB773p1VVVWlyMhIZWZmBo/1799fI0aMUFVVlSRpxowZuvfee7Vx40aNHz9eBQUFGj16tCTp3nvvVUFBgf79738rNzdXU6ZMCYaSk7gHBwCAbuRyuRQbHdkjj3P5lOD27tsxxgRf7+6779bHH3+swsJCVVRUaMyYMfrtb38rScrPz9eBAwdUXFysw4cP6wc/+IEefvjhc9/As0TgAACAdqWnp6uxsVHbt28PHjt+/Lj++9//Ki0tLXgsJSVFRUVFWrNmjX7xi1+orKws+NyAAQN0xx136I9//KOWLl2q5557zvF58ysqAADQruHDh2vy5MmaPn26fve73ykuLk5z5szRpZdeqsmTJ0uSiouLlZ+fr+985zs6ceKENm/eHIyfX/7yl8rIyNAVV1yhuro6/e1vfwsJI6dwBQcAAHToxRdfVEZGhiZOnKisrCwZY7R+/XpFRUVJkpqamnT//fcrLS1NeXl5GjFihJYvXy5Jio6O1ty5czV69Ghde+21ioiI0KpVqxyfs8uc65viw1ggEJDH45Hf71d8fHxPTwcAYLGvvvpK1dXVSk1NVUxMTE9Pp9fraL868/ObKzgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAdIML8D0956Sr9onAAQDAQS1vpT558mQPzyQ81NfXS5IiIjr/z0p8HR/0BwCAgyIiInTJJZfoyJEjkqTY2Nhz+icTLgTNzc06evSoYmNjFRl5folC4AAA4LCkpCRJCkYO2tenTx8NHjz4vCOQwAEAwGEul0uDBg3SwIED1dDQ0NPT6dWio6PVp8/530FD4AAA0E0iIiLO+94SnB1uMgYAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGCdbgmc5cuXKzU1VTExMcrIyNDWrVs7HL9lyxZlZGQoJiZGw4YN04oVK9odu2rVKrlcLk2ZMqWLZw0AAMKV44Hz6quvqri4WI899ph27dqlnJwc5efn6+DBg22Or66u1g033KCcnBzt2rVLjz76qGbMmKHVq1e3GnvgwAE9/PDDysnJcXoZAAAgjLiMMcbJb5CZmamrr75azz77bPBYWlqapkyZopKSklbjZ8+erXXr1qmqqip4rKioSHv27JHX6w0ea2pq0rhx43TnnXdq69at+uKLL/T666+f1ZwCgYA8Ho/8fr/i4+PPfXEAAKDbdObnt6NXcOrr67Vz507l5uaGHM/NzVV5eXmb53i93lbjJ0yYoB07dqihoSF4bMGCBRowYIDuuuuuM86jrq5OgUAg5AEAAOzlaOAcO3ZMTU1NSkxMDDmemJgon8/X5jk+n6/N8Y2NjTp27Jgk6e2339bKlStVVlZ2VvMoKSmRx+MJPlJSUs5hNQAAIFx0y03GLpcr5GtjTKtjZxrfcry2tla33XabysrKlJCQcFbff+7cufL7/cHHoUOHOrkCAAAQTiKdfPGEhARFRES0ulpz5MiRVldpWiQlJbU5PjIyUv3799fevXu1f/9+TZo0Kfh8c3OzJCkyMlL79u3T5ZdfHnK+2+2W2+3uiiUBAIAw4OgVnOjoaGVkZGjTpk0hxzdt2qTs7Ow2z8nKymo1fuPGjRozZoyioqI0cuRIVVRUaPfu3cHHjTfeqO9973vavXs3v34CAADOXsGRpFmzZqmwsFBjxoxRVlaWnnvuOR08eFBFRUWSTv/66NNPP9Uf/vAHSaffMVVaWqpZs2Zp+vTp8nq9WrlypV555RVJUkxMjEaNGhXyPS655BJJanUcAABcmBwPnKlTp+r48eNasGCBampqNGrUKK1fv15DhgyRJNXU1IR8Jk5qaqrWr1+vmTNnatmyZUpOTtYzzzyjgoICp6cKAAAs4fjn4PRGfA4OAADhp9d8Dg4AAEBPIHAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgHQIHAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWKdbAmf58uVKTU1VTEyMMjIytHXr1g7Hb9myRRkZGYqJidGwYcO0YsWKkOfLysqUk5Ojfv36qV+/fho/frzeeecdJ5cAAADCiOOB8+qrr6q4uFiPPfaYdu3apZycHOXn5+vgwYNtjq+urtYNN9ygnJwc7dq1S48++qhmzJih1atXB8e89dZbuuWWW/SPf/xDXq9XgwcPVm5urj799FOnlwMAAMKAyxhjnPwGmZmZuvrqq/Xss88Gj6WlpWnKlCkqKSlpNX727Nlat26dqqqqgseKioq0Z88eeb3eNr9HU1OT+vXrp9LSUv3sZz8745wCgYA8Ho/8fr/i4+PPYVUAAKC7debnt6NXcOrr67Vz507l5uaGHM/NzVV5eXmb53i93lbjJ0yYoB07dqihoaHNc06ePKmGhgZ961vfavP5uro6BQKBkAcAALCXo4Fz7NgxNTU1KTExMeR4YmKifD5fm+f4fL42xzc2NurYsWNtnjNnzhxdeumlGj9+fJvPl5SUyOPxBB8pKSnnsBoAABAuuuUmY5fLFfK1MabVsTONb+u4JC1ZskSvvPKK1qxZo5iYmDZfb+7cufL7/cHHoUOHOrsEAAAQRiKdfPGEhARFRES0ulpz5MiRVldpWiQlJbU5PjIyUv379w85/tRTT2nhwoV68803NXr06Hbn4Xa75Xa7z3EVAAAg3Dh6BSc6OloZGRnatGlTyPFNmzYpOzu7zXOysrJajd+4caPGjBmjqKio4LFf/epXevLJJ7VhwwaNGTOm6ycPAADCluO/opo1a5aef/55vfDCC6qqqtLMmTN18OBBFRUVSTr966Ovv/OpqKhIBw4c0KxZs1RVVaUXXnhBK1eu1MMPPxwcs2TJEj3++ON64YUXNHToUPl8Pvl8Pv3vf/9zejkAACAMOPorKkmaOnWqjh8/rgULFqimpkajRo3S+vXrNWTIEElSTU1NyGfipKamav369Zo5c6aWLVum5ORkPfPMMyooKAiOWb58uerr6/XjH/845HvNmzdP8+fPd3pJAACgl3P8c3B6Iz4HBwCA8NNrPgcHAACgJxA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKzTLYGzfPlypaamKiYmRhkZGdq6dWuH47ds2aKMjAzFxMRo2LBhWrFiRasxq1evVnp6utxut9LT07V27Vqnpg8AAMKM44Hz6quvqri4WI899ph27dqlnJwc5efn6+DBg22Or66u1g033KCcnBzt2rVLjz76qGbMmKHVq1cHx3i9Xk2dOlWFhYXas2ePCgsL9dOf/lTbt293ejkAACAMuIwxxslvkJmZqauvvlrPPvts8FhaWpqmTJmikpKSVuNnz56tdevWqaqqKnisqKhIe/bskdfrlSRNnTpVgUBAb7zxRnBMXl6e+vXrp1deeeWMcwoEAvJ4PPL7/YqPjz+f5QEAgG7SmZ/fjl7Bqa+v186dO5WbmxtyPDc3V+Xl5W2e4/V6W42fMGGCduzYoYaGhg7HtPeadXV1CgQCIQ8AAGAvRwPn2LFjampqUmJiYsjxxMRE+Xy+Ns/x+Xxtjm9sbNSxY8c6HNPea5aUlMjj8QQfKSkp57okAAAQBrrlJmOXyxXytTGm1bEzjf/m8c685ty5c+X3+4OPQ4cOdWr+AAAgvEQ6+eIJCQmKiIhodWXlyJEjra7AtEhKSmpzfGRkpPr379/hmPZe0+12y+12n+syAABAmHH0Ck50dLQyMjK0adOmkOObNm1SdnZ2m+dkZWW1Gr9x40aNGTNGUVFRHY5p7zUBAMCFxdErOJI0a9YsFRYWasyYMcrKytJzzz2ngwcPqqioSNLpXx99+umn+sMf/iDp9DumSktLNWvWLE2fPl1er1crV64MeXfUQw89pGuvvVaLFy/W5MmT9de//lVvvvmm/vWvfzm9HAAAEAYcD5ypU6fq+PHjWrBggWpqajRq1CitX79eQ4YMkSTV1NSEfCZOamqq1q9fr5kzZ2rZsmVKTk7WM888o4KCguCY7OxsrVq1So8//rieeOIJXX755Xr11VeVmZnp9HIAAEAYcPxzcHojPgcHAIDw02s+BwcAAKAnEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArONo4Jw4cUKFhYXyeDzyeDwqLCzUF1980eE5xhjNnz9fycnJ6tu3r6677jrt3bs3+Pznn3+uBx98UCNGjFBsbKwGDx6sGTNmyO/3O7kUAAAQRhwNnGnTpmn37t3asGGDNmzYoN27d6uwsLDDc5YsWaKnn35apaWlevfdd5WUlKTrr79etbW1kqTDhw/r8OHDeuqpp1RRUaHf//732rBhg+666y4nlwIAAMKIyxhjnHjhqqoqpaena9u2bcrMzJQkbdu2TVlZWXr//fc1YsSIVucYY5ScnKzi4mLNnj1bklRXV6fExEQtXrxY99xzT5vf67XXXtNtt92mL7/8UpGRkWecWyAQkMfjkd/vV3x8/HmsEgAAdJfO/Px27AqO1+uVx+MJxo0kjR07Vh6PR+Xl5W2eU11dLZ/Pp9zc3OAxt9utcePGtXuOpOBCzyZuAACA/RwrAp/Pp4EDB7Y6PnDgQPl8vnbPkaTExMSQ44mJiTpw4ECb5xw/flxPPvlku1d3pNNXgerq6oJfBwKBM84fAACEr05fwZk/f75cLleHjx07dkiSXC5Xq/ONMW0e/7pvPt/eOYFAQD/84Q+Vnp6uefPmtft6JSUlwRudPR6PUlJSzmapAAAgTHX6Cs4DDzygm2++ucMxQ4cO1XvvvafPPvus1XNHjx5tdYWmRVJSkqTTV3IGDRoUPH7kyJFW59TW1iovL08XX3yx1q5dq6ioqHbnM3fuXM2aNSv4dSAQIHIAALBYpwMnISFBCQkJZxyXlZUlv9+vd955R9dcc40kafv27fL7/crOzm7znNTUVCUlJWnTpk266qqrJEn19fXasmWLFi9eHBwXCAQ0YcIEud1urVu3TjExMR3Oxe12y+12n+0SAQBAmHPsJuO0tDTl5eVp+vTp2rZtm7Zt26bp06dr4sSJIe+gGjlypNauXSvp9K+miouLtXDhQq1du1b/+c9/dMcddyg2NlbTpk2TdPrKTW5urr788kutXLlSgUBAPp9PPp9PTU1NTi0HAACEEUffdvTyyy9rxowZwXdF3XjjjSotLQ0Zs2/fvpAP6XvkkUd06tQp3XfffTpx4oQyMzO1ceNGxcXFSZJ27typ7du3S5K+/e1vh7xWdXW1hg4d6uCKAABAOHDsc3B6Mz4HBwCA8NMrPgcHAACgpxA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOs4GjgnTpxQYWGhPB6PPB6PCgsL9cUXX3R4jjFG8+fPV3Jysvr27avrrrtOe/fubXdsfn6+XC6XXn/99a5fAAAACEuOBs60adO0e/dubdiwQRs2bNDu3btVWFjY4TlLlizR008/rdLSUr377rtKSkrS9ddfr9ra2lZjly5dKpfL5dT0AQBAmIp06oWrqqq0YcMGbdu2TZmZmZKksrIyZWVlad++fRoxYkSrc4wxWrp0qR577DHddNNNkqSXXnpJiYmJ+tOf/qR77rknOHbPnj16+umn9e6772rQoEFOLQMAAIQhx67geL1eeTyeYNxI0tixY+XxeFReXt7mOdXV1fL5fMrNzQ0ec7vdGjduXMg5J0+e1C233KLS0lIlJSWdcS51dXUKBAIhDwAAYC/HAsfn82ngwIGtjg8cOFA+n6/dcyQpMTEx5HhiYmLIOTNnzlR2drYmT558VnMpKSkJ3gfk8XiUkpJytssAAABhqNOBM3/+fLlcrg4fO3bskKQ2748xxpzxvplvPv/1c9atW6fNmzdr6dKlZz3nuXPnyu/3Bx+HDh0663MBAED46fQ9OA888IBuvvnmDscMHTpU7733nj777LNWzx09erTVFZoWLb9u8vl8IffVHDlyJHjO5s2b9dFHH+mSSy4JObegoEA5OTl66623Wr2u2+2W2+3ucM4AAMAenQ6chIQEJSQknHFcVlaW/H6/3nnnHV1zzTWSpO3bt8vv9ys7O7vNc1JTU5WUlKRNmzbpqquukiTV19dry5YtWrx4sSRpzpw5uvvuu0POu/LKK/XrX/9akyZN6uxyAACAhRx7F1VaWpry8vI0ffp0/e53v5Mk/fznP9fEiRND3kE1cuRIlZSU6Ec/+pFcLpeKi4u1cOFCDR8+XMOHD9fChQsVGxuradOmSTp9laetG4sHDx6s1NRUp5YDAADCiGOBI0kvv/yyZsyYEXxX1I033qjS0tKQMfv27ZPf7w9+/cgjj+jUqVO67777dOLECWVmZmrjxo2Ki4tzcqoAAMAiLmOM6elJdLdAICCPxyO/36/4+Pieng4AADgLnfn5zb9FBQAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrEDgAAMA6BA4AALAOgQMAAKxD4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgAAAA6xA4AADAOgQOAACwDoEDAACsQ+AAAADrRPb0BHqCMUaSFAgEengmAADgbLX83G75Od6RCzJwamtrJUkpKSk9PBMAANBZtbW18ng8HY5xmbPJIMs0Nzfr8OHDiouLk8vl6unp9LhAIKCUlBQdOnRI8fHxPT0da7HP3YN97j7sdfdgn/8/Y4xqa2uVnJysPn06vsvmgryC06dPH1122WU9PY1eJz4+/oL/j6c7sM/dg33uPux192CfTzvTlZsW3GQMAACsQ+AAAADrEDiQ2+3WvHnz5Ha7e3oqVmOfuwf73H3Y6+7BPp+bC/ImYwAAYDeu4AAAAOsQOAAAwDoEDgAAsA6BAwAArEPgXABOnDihwsJCeTweeTweFRYW6osvvujwHGOM5s+fr+TkZPXt21fXXXed9u7d2+7Y/Px8uVwuvf76612/gDDhxD5//vnnevDBBzVixAjFxsZq8ODBmjFjhvx+v8Or6V2WL1+u1NRUxcTEKCMjQ1u3bu1w/JYtW5SRkaGYmBgNGzZMK1asaDVm9erVSk9Pl9vtVnp6utauXevU9MNGV+9zWVmZcnJy1K9fP/Xr10/jx4/XO++84+QSwoITf55brFq1Si6XS1OmTOniWYchA+vl5eWZUaNGmfLyclNeXm5GjRplJk6c2OE5ixYtMnFxcWb16tWmoqLCTJ061QwaNMgEAoFWY59++mmTn59vJJm1a9c6tIrez4l9rqioMDfddJNZt26d+fDDD83f//53M3z4cFNQUNAdS+oVVq1aZaKiokxZWZmprKw0Dz30kLnooovMgQMH2hz/8ccfm9jYWPPQQw+ZyspKU1ZWZqKiosxf/vKX4Jjy8nITERFhFi5caKqqqszChQtNZGSk2bZtW3ctq9dxYp+nTZtmli1bZnbt2mWqqqrMnXfeaTwej/nkk0+6a1m9jhP73GL//v3m0ksvNTk5OWby5MkOr6T3I3AsV1lZaSSF/I/b6/UaSeb9999v85zm5maTlJRkFi1aFDz21VdfGY/HY1asWBEydvfu3eayyy4zNTU1F3TgOL3PX/fnP//ZREdHm4aGhq5bQC92zTXXmKKiopBjI0eONHPmzGlz/COPPGJGjhwZcuyee+4xY8eODX7905/+1OTl5YWMmTBhgrn55pu7aNbhx4l9/qbGxkYTFxdnXnrppfOfcJhyap8bGxvNd7/7XfP888+b22+/ncAxxvArKst5vV55PB5lZmYGj40dO1Yej0fl5eVtnlNdXS2fz6fc3NzgMbfbrXHjxoWcc/LkSd1yyy0qLS1VUlKSc4sIA07u8zf5/X7Fx8crMtL+f0quvr5eO3fuDNkjScrNzW13j7xeb6vxEyZM0I4dO9TQ0NDhmI723WZO7fM3nTx5Ug0NDfrWt77VNRMPM07u84IFCzRgwADdddddXT/xMEXgWM7n82ngwIGtjg8cOFA+n6/dcyQpMTEx5HhiYmLIOTNnzlR2drYmT57chTMOT07u89cdP35cTz75pO65557znHF4OHbsmJqamjq1Rz6fr83xjY2NOnbsWIdj2ntN2zm1z980Z84cXXrppRo/fnzXTDzMOLXPb7/9tlauXKmysjJnJh6mCJwwNX/+fLlcrg4fO3bskCS5XK5W5xtj2jz+dd98/uvnrFu3Tps3b9bSpUu7ZkG9VE/v89cFAgH98Ic/VHp6uubNm3ceqwo/Z7tHHY3/5vHOvuaFwIl9brFkyRK98sorWrNmjWJiYrpgtuGrK/e5trZWt912m8rKypSQkND1kw1j9l/jttQDDzygm2++ucMxQ4cO1XvvvafPPvus1XNHjx5t9beCFi2/bvL5fBo0aFDw+JEjR4LnbN68WR999JEuueSSkHMLCgqUk5Ojt956qxOr6b16ep9b1NbWKi8vTxdffLHWrl2rqKiozi4lLCUkJCgiIqLV327b2qMWSUlJbY6PjIxU//79OxzT3mvazql9bvHUU09p4cKFevPNNzV69OiunXwYcWKf9+7dq/3792vSpEnB55ubmyVJkZGR2rdvny6//PIuXkmY6KF7f9BNWm5+3b59e/DYtm3bzurm18WLFweP1dXVhdz8WlNTYyoqKkIeksxvfvMb8/HHHzu7qF7IqX02xhi/32/Gjh1rxo0bZ7788kvnFtFLXXPNNebee+8NOZaWltbhTZlpaWkhx4qKilrdZJyfnx8yJi8v74K/ybir99kYY5YsWWLi4+ON1+vt2gmHqa7e51OnTrX6f/HkyZPN97//fVNRUWHq6uqcWUgYIHAuAHl5eWb06NHG6/Uar9drrrzyylZvXx4xYoRZs2ZN8OtFixYZj8dj1qxZYyoqKswtt9zS7tvEW+gCfheVMc7scyAQMJmZmebKK680H374oampqQk+Ghsbu3V9PaXlbbUrV640lZWVpri42Fx00UVm//79xhhj5syZYwoLC4PjW95WO3PmTFNZWWlWrlzZ6m21b7/9tomIiDCLFi0yVVVVZtGiRbxN3IF9Xrx4sYmOjjZ/+ctfQv7s1tbWdvv6egsn9vmbeBfVaQTOBeD48ePm1ltvNXFxcSYuLs7ceuut5sSJEyFjJJkXX3wx+HVzc7OZN2+eSUpKMm6321x77bWmoqKiw+9zoQeOE/v8j3/8w0hq81FdXd09C+sFli1bZoYMGWKio6PN1VdfbbZs2RJ87vbbbzfjxo0LGf/WW2+Zq666ykRHR5uhQ4eaZ599ttVrvvbaa2bEiBEmKirKjBw50qxevdrpZfR6Xb3PQ4YMafPP7rx587phNb2XE3+ev47AOc1lzP+7WwkAAMASvIsKAABYh8ABAADWIXAAAIB1CBwAAGAdAgcAAFiHwAEAANYhcAAAgHUIHAAAYB0CBwAAWIfAAQAA1iFwAACAdQgcAABgnf8Lf7QmZOX0CW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(schedule_hist, label='learning rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(loss_hist, label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

import pandas as pd
import re
from shekar import Normalizer
 
df = pd.read_csv("samsung_comments_labeled_binary.csv")

 
normalizer = Normalizer()

def clean_text(text):
    if not isinstance(text, str):
        return ""
    # حذف لینک‌ها
    text = re.sub(r"http\S+|www\S+", " ", text)
    # حذف ایموجی‌ها و کاراکترهای غیر متنی
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    # حذف اعداد
    text = re.sub(r"\d+", " ", text)
    # نرمال‌سازی حروف فارسی (ي→ی، ك→ک و ...)
    text = normalizer.normalize(text)
    # حذف فاصله‌های اضافی
    text = re.sub(r"\s+", " ", text).strip()
    return text

# --- Apply cleaning to every row ---
df["clean_body"] = df["body"].apply(clean_text)
print(df.head())



from transformers import AutoTokenizer, AutoModel
import numpy as np
from tqdm import tqdm
 
model_name = "HooshvareLab/bert-base-parsbert-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model.eval()


def get_parsbert_embedding(text, tokenizer, model, device):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=512
    )
    inputs = {k:v.to(device) for k,v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
    
    embedding = outputs.last_hidden_state[:,0,:].squeeze().cpu().numpy()
    return embedding
 
def batch_embeddings(texts, tokenizer, model, device, batch_size=16):
    all_embeddings = [] 
    for i in tqdm(range(0, len(texts), batch_size), desc="Embedding batches"):
        batch_texts = texts[i:i+batch_size]
        batch_emb = [get_parsbert_embedding(t, tokenizer, model, device) for t in batch_texts]
        all_embeddings.extend(batch_emb)
    return all_embeddings


texts = df["clean_body"].tolist()
 
embeddings = batch_embeddings(texts, tokenizer, model, device, batch_size=16)
 
df["embedding"] = embeddings
 
np.save("embeddings.npy", np.stack(embeddings))

print("Embedding ها ساخته و ذخیره شدند ✅")


X = np.stack(df['embedding'].values)  # شکل: (9531, 768)

print("نوع داده:", type(X))
print("شکل داده:", X.shape)



y = df['label'].map({'مثبت': 1, 'منفی': 0})
print(y)


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))


from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)
import seaborn as sns
import matplotlib.pyplot as plt

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy :", acc)
print("Precision:", prec)
print("Recall   :", rec)
print("F1-score :", f1)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

 
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["منفی","مثبت"], yticklabels=["منفی","مثبت"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


from sklearn.svm import SVC

svm = SVC(kernel='linear', probability=True)
svm.fit(X_train, y_train)

y_pred = svm.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))


acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy :", acc)
print("Precision:", prec)
print("Recall   :", rec)
print("F1-score :", f1)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

 
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["منفی","مثبت"], yticklabels=["منفی","مثبت"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


text= "گوشی خوبی هستش"
emb=get_parsbert_embedding(text, tokenizer, model, device)
emb_2d = emb.reshape(1, -1)

y_pred_svm = svm.predict(emb_2d)
y_pred_lg = clf.predict(emb_2d)

print("نتیجه SVM:", y_pred_svm)
print("نتیجه LinearRegression:", y_pred_lg)







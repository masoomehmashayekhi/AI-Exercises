import requests
import csv
import time

BASE_URL = "https://api.digikala.com/v1"
SEARCH_URL = f"{BASE_URL}/categories/mobile-phone/brands/samsung/search/"
COMMENT_URL = "{}/product/{}/comments/".format(BASE_URL, "{}")
HEADERS = {"User-Agent": "Mozilla/5.0"}


def get_products(page):
    url = f"{SEARCH_URL}?page={page}"
    r = requests.get(url, headers=HEADERS, timeout=10)
    if r.status_code != 200:
        print(f"âš ï¸ ØµÙØ­Ù‡ {page} Ø®Ø·Ø§ Ø¯Ø§Ø¯ ({r.status_code})")
        return []
    data = r.json()
    return data.get("data", {}).get("products", [])


def get_comments(product_id):
    url = COMMENT_URL.format(product_id)
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        r.raise_for_status()
    except requests.RequestException as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ {url}: {e}")
        return []

    try:
        data = r.json()
    except ValueError:
        print(f"âš ï¸ Ù¾Ø§Ø³Ø® JSON Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id}")
        return []

    # ğŸ”¹ Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø­Ù„ commentÙ‡Ø§
    comments = None
    if "comments" in data:
        comments = data["comments"]
    elif "data" in data and "comments" in data["data"]:
        comments = data["data"]["comments"]
    elif "data" in data and isinstance(data["data"], list):
        for item in data["data"]:
            if "comments" in item:
                comments = item["comments"]
                break
    elif "data" in data and isinstance(data["data"], dict): 
        comments = data["data"].get("comments", [])

    if not comments:
        print(f"âš ï¸ Ù‡ÛŒÚ† Ù†Ø¸Ø±ÛŒ Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        print("ğŸ” Ø³Ø§Ø®ØªØ§Ø± Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§:", list(data.keys()))
        return []

    print(f"âœ… {len(comments)} Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {product_id} ÛŒØ§ÙØª Ø´Ø¯.")
    return comments


# --- ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ CSV ---
with open("samsung_comments.csv", "a", newline='', encoding="utf-8") as f:
    writer = csv.writer(f)

    # --- Ù…Ø±Ø­Ù„Ù‡ Û±: Ù…Ø±ÙˆØ± ØµÙØ­Ø§Øª ---
    for page in range(1, 101):
        print(f"ğŸ“„ ØµÙØ­Ù‡ {page} Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ...")
        products = get_products(page)
        if not products:
            print("â›” ØµÙØ­Ù‡ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯. Ù¾Ø§ÛŒØ§Ù†.")

        # --- Ù…Ø±Ø­Ù„Ù‡ Û²: Ø¯Ø±ÛŒØ§ÙØª Ú©Ø§Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ù…Ø­ØµÙˆÙ„ ---
        for product in products:
            pid = product.get("id")
            pname = product.get("title_fa")
            comments = get_comments(pid)

            if not comments:
                print(f"  âŒ Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø±: {pname} {pid}")
                continue

            for c in comments:
                writer.writerow([
                    c.get("body"),
                    c.get("created_at"),
                    c.get("rate"),
                    pname,
                    c.get("user_name"),
                ])

            print(f"  âœ… {len(comments)} Ù†Ø¸Ø± Ø§Ø² '  {pname}{pid}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
            time.sleep(1)  # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù† ØªÙˆØ³Ø· Ø³Ø±ÙˆØ±

        time.sleep(2)

print("ğŸ‰ ØªÙ…Ø§Ù… Ù†Ø¸Ø±Ø§Øª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯ â†’ samsung_comments.csv")







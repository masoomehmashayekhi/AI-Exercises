get_ipython().run_line_magic("matplotlib", " inline")
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import numpy as np


# Generate some data
from sklearn.datasets import make_blobs
X, y_true = make_blobs(n_samples=400, centers=4,
                       cluster_std=0.60, random_state=0)
X = X[:, ::-1] # flip axes for better plotting


plt.scatter(X[:, 0], X[:, 1]);


from matplotlib.patches import Ellipse

def draw_ellipse(position, covariance, ax=None, **kwargs):
    """Draw an ellipse with a given position and covariance"""
    ax = ax or plt.gca()
    
    # Convert covariance to principal axes
    if covariance.shape == (2, 2):
        U, s, Vt = np.linalg.svd(covariance)
        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))
        width, height = 2 * np.sqrt(s)
    else:
        angle = 0
        width, height = 2 * np.sqrt(covariance)
    
    # Draw the Ellipse
    for nsig in range(1, 4):
        ax.add_patch(Ellipse(xy=position, width=nsig * width, 
                             height=nsig * height, angle=angle, **kwargs))
        
def plot_gmm(gmm, X, label=True, ax=None):
    ax = ax or plt.gca()
    labels = gmm.predict(X) # complete here
    if label:
        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
    else:
        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)
    ax.axis('equal')
    
    w_factor = 0.2 / gmm.weights_.max()
    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):
        draw_ellipse(pos, covar, alpha=w * w_factor) # complete here


from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=4, random_state=0)
labels_kmeans = kmeans.fit_predict(X)


plt.scatter(X[:, 0], X[:, 1], c=labels_kmeans, cmap='viridis', s=30)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
            c='red', marker='x', s=100)
plt.title("KMeans Clustering Result")
plt.show()


from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(n_components=4, covariance_type='full', random_state=0)
gmm.fit(X)

labels_gmm = gmm.predict(X)
plt.scatter(X[:, 0], X[:, 1], c=labels_gmm, cmap='viridis', s=30)
plt.title("GMM Clustering Result")
plt.show()


probs = gmm.predict_proba(X)
print(probs)


size = 40 * probs.max(axis=1)  # هرچه احتمال بیشتر، دایره بزرگ‌تر
plt.scatter(X[:, 0], X[:, 1], c=labels_gmm, s=size, cmap='viridis')
plt.title("Points Sized by Cluster Membership Probability")
plt.show()


plt.figure(figsize=(8, 6))
plot_gmm(gmm, X, label=True)
plt.title("Gaussian Mixture Model Visualization with Ellipses")
plt.show()




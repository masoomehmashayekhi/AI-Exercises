{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad4885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2e2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./17flowers_dataset\"\n",
    "\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fdeccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/aima138/17flowerclasses\n",
      "Dataset downloaded and extracted to: ./17flowers_dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading dataset...\")\n",
    "api.dataset_download_files('aima138/17flowerclasses', path=dataset_path, unzip=True)\n",
    "print(\"Dataset downloaded and extracted to:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f2457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = dataset_path \n",
    "train_dir = os.path.join(dataset_dir,\"17flowerclasses\", \"train\")\n",
    "test_dir  = os.path.join(dataset_dir,\"17flowerclasses\" ,\"test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ecfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (160, 160)   \n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_EPOCHS_HEAD = 20\n",
    "NUM_EPOCHS_FINETUNE = 20\n",
    "PATIENCE = 5\n",
    "MODEL_SAVE_PATH = \"flower17_model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113f9f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1190 files belonging to 17 classes.\n",
      "Found 170 files belonging to 17 classes.\n",
      "Classes: ['Bluebell', 'ButterCup', 'ColtsFoot', 'Cowslip', 'Crocus', 'Daffodil', 'Daisy', 'Dandelion', 'Fritillary', 'Iris', 'LilyValley', 'Pansy', 'Snowdrop', 'Sunflower', 'Tigerlily', 'WindFlower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f71772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.15),\n",
    "])\n",
    "\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "def prepare(ds, training=False):\n",
    "    ds = ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = prepare(train_ds, training=True)\n",
    "val_ds   = prepare(val_ds, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cbb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010b213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = data_augmentation(inputs)           \n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6faff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, 5, 5, 1280)        4049571   \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 17)                21777     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4071348 (15.53 MB)\n",
      "Trainable params: 4029325 (15.37 MB)\n",
      "Non-trainable params: 42023 (164.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b2e2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(MODEL_SAVE_PATH, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=PATIENCE, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f64558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 1.4506 - accuracy: 0.5513\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74706, saving model to flower17_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M_Mashayekhi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 163s 3s/step - loss: 1.4506 - accuracy: 0.5513 - val_loss: 0.8470 - val_accuracy: 0.7471\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.8353\n",
      "Epoch 2: val_accuracy improved from 0.74706 to 0.81765, saving model to flower17_model.h5\n",
      "38/38 [==============================] - 119s 3s/step - loss: 0.5410 - accuracy: 0.8353 - val_loss: 0.6011 - val_accuracy: 0.8176\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8773\n",
      "Epoch 3: val_accuracy improved from 0.81765 to 0.83529, saving model to flower17_model.h5\n",
      "38/38 [==============================] - 110s 3s/step - loss: 0.4148 - accuracy: 0.8773 - val_loss: 0.6086 - val_accuracy: 0.8353\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8882\n",
      "Epoch 4: val_accuracy did not improve from 0.83529\n",
      "38/38 [==============================] - 111s 3s/step - loss: 0.3811 - accuracy: 0.8882 - val_loss: 0.5258 - val_accuracy: 0.8353\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.9118\n",
      "Epoch 5: val_accuracy improved from 0.83529 to 0.84706, saving model to flower17_model.h5\n",
      "38/38 [==============================] - 102s 3s/step - loss: 0.2907 - accuracy: 0.9118 - val_loss: 0.4890 - val_accuracy: 0.8471\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.9303\n",
      "Epoch 6: val_accuracy improved from 0.84706 to 0.90000, saving model to flower17_model.h5\n",
      "38/38 [==============================] - 104s 3s/step - loss: 0.2126 - accuracy: 0.9303 - val_loss: 0.3271 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9546\n",
      "Epoch 7: val_accuracy did not improve from 0.90000\n",
      "38/38 [==============================] - 107s 3s/step - loss: 0.1744 - accuracy: 0.9546 - val_loss: 0.6228 - val_accuracy: 0.8176\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9597\n",
      "Epoch 8: val_accuracy did not improve from 0.90000\n",
      "38/38 [==============================] - 105s 3s/step - loss: 0.1256 - accuracy: 0.9597 - val_loss: 0.6024 - val_accuracy: 0.8529\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9773\n",
      "Epoch 9: val_accuracy improved from 0.90000 to 0.92941, saving model to flower17_model.h5\n",
      "38/38 [==============================] - 109s 3s/step - loss: 0.0877 - accuracy: 0.9773 - val_loss: 0.1811 - val_accuracy: 0.9294\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9664\n",
      "Epoch 10: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 110s 3s/step - loss: 0.1060 - accuracy: 0.9664 - val_loss: 0.7832 - val_accuracy: 0.8235\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9471\n",
      "Epoch 11: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 101s 3s/step - loss: 0.1773 - accuracy: 0.9471 - val_loss: 0.6080 - val_accuracy: 0.8235\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9134\n",
      "Epoch 12: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 102s 3s/step - loss: 0.2533 - accuracy: 0.9134 - val_loss: 0.3503 - val_accuracy: 0.8882\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9672\n",
      "Epoch 13: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 104s 3s/step - loss: 0.1239 - accuracy: 0.9672 - val_loss: 0.4433 - val_accuracy: 0.9235\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9580\n",
      "Epoch 14: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 96s 2s/step - loss: 0.1426 - accuracy: 0.9580 - val_loss: 0.4653 - val_accuracy: 0.8941\n"
     ]
    }
   ],
   "source": [
    "history_head = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=NUM_EPOCHS_HEAD,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62815572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9899\n",
      "Epoch 1: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 130s 3s/step - loss: 0.0271 - accuracy: 0.9899 - val_loss: 0.1844 - val_accuracy: 0.9235\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9966\n",
      "Epoch 2: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 121s 3s/step - loss: 0.0208 - accuracy: 0.9966 - val_loss: 0.2090 - val_accuracy: 0.9118\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 3: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 114s 3s/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.2455 - val_accuracy: 0.9118\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 4: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 115s 3s/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.2382 - val_accuracy: 0.9118\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 5: val_accuracy did not improve from 0.92941\n",
      "38/38 [==============================] - 111s 3s/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.2461 - val_accuracy: 0.9176\n",
      "Epoch 6/20\n",
      " 9/38 [======>.......................] - ETA: 1:26 - loss: 0.0164 - accuracy: 0.9965"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True \n",
    "   \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=NUM_EPOCHS_FINETUNE,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c41539",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(val_ds)\n",
    "print(f\"Final val loss: {loss:.4f}  val acc: {acc:.4f}\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_SAVE_PATH)\n",
    "print(\"Saved model to\", MODEL_SAVE_PATH)\n",
    " \n",
    "def plot_history(h1, h2=None):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    # accuracy\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h1.history['accuracy'], label='train_acc_head')\n",
    "    plt.plot(h1.history['val_accuracy'], label='val_acc_head')\n",
    "    if h2:\n",
    "        plt.plot(range(len(h1.history['accuracy']), len(h1.history['accuracy'])+len(h2.history['accuracy'])),\n",
    "                 h2.history['accuracy'], label='train_acc_finetune')\n",
    "        plt.plot(range(len(h1.history['val_accuracy']), len(h1.history['val_accuracy'])+len(h2.history['val_accuracy'])),\n",
    "                 h2.history['val_accuracy'], label='val_acc_finetune')\n",
    "    plt.legend(); plt.title(\"Accuracy\")\n",
    "    # loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h1.history['loss'], label='train_loss_head')\n",
    "    plt.plot(h1.history['val_loss'], label='val_loss_head')\n",
    "    if h2:\n",
    "        plt.plot(range(len(h1.history['loss']), len(h1.history['loss'])+len(h2.history['loss'])),\n",
    "                 h2.history['loss'], label='train_loss_finetune')\n",
    "        plt.plot(range(len(h1.history['val_loss']), len(h1.history['val_loss'])+len(h2.history['val_loss'])),\n",
    "                 h2.history['val_loss'], label='val_loss_finetune')\n",
    "    plt.legend(); plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_head, history_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd3878",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "external_images = [\n",
    "    \"external1.jpg\",\n",
    "    \"external2.jpg\",\n",
    "    \"external3.jpg\"\n",
    "]\n",
    "# مطمئن شو این فایل‌ها در همان پوشه اسکریپت یا مسیر درست قرار دارند.\n",
    "plt.figure(figsize=(12,4))\n",
    "for i, img_path in enumerate(external_images):\n",
    "    if not Path(img_path).exists():\n",
    "        print(\"File not found:\", img_path)\n",
    "        continue\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    pred_label = class_names[np.argmax(preds)]\n",
    "    pred_conf  = float(np.max(preds))\n",
    "\n",
    "    plt.subplot(1, len(external_images), i+1)\n",
    "    plt.imshow((image.img_to_array(img)/255.).astype(np.float32))\n",
    "    plt.title(f\"{pred_label}\\n{pred_conf:.2f}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

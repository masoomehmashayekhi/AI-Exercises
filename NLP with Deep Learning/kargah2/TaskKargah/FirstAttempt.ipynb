{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a16b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ywinpty (D:\\Mas\\anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ywinpty (D:\\Mas\\anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ywinpty (D:\\Mas\\anaconda\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers rapidfuzz shekar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9750211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Mas\\anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rapidfuzz import fuzz\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec80f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIAN_STOPWORDS = {\n",
    "    \"شرکت\",\"موسسه\",\"گروه\",\"صنعت\",\"صنایع\",\"توسعه\",\"مهندسی\",\"فناوری\",\"نوین\",\n",
    "    \"تک\",\"ارتباط\",\"مبین\",\"پیشرفته\",\"گسترش\",\"مرکز\",\"هولدینگ\",\n",
    "    \"مدرن\",\"نو\",\"جدید\",\"پژوهش\",\"کاربردی\",\"راهکار\",\"راه\",\"راه‌حل\",\n",
    "    \"اندیشه\",\"سامانه\",\"خدمات\",\"تجارت\",\"تجاری\",\"بازرگانی\",\"کو\",\"ایران\",\n",
    "   \"و\", \"در\", \"با\", \"از\",\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b79d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shekar import Normalizer, Lemmatizer, WordTokenizer\n",
    "import re\n",
    "from cleantext import clean\n",
    "\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "def preprocess_and_stem(text): \n",
    "    text = normalizer.normalize(text) \n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = text.replace(\"\\u200c\", \"\")\n",
    "    text = str(clean(text,\n",
    "                           clean_all= False  ,\n",
    "                           extra_spaces=True ,     \n",
    "                           numbers=True ,  \n",
    "                           punct=True      \n",
    "                           ))\n",
    "     \n",
    "    tokens = list(tokenizer(text))\n",
    "     \n",
    "    stems =  [lemmatizer(t) for t in tokens if t not in PERSIAN_STOPWORDS]\n",
    "    return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11fbe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6C08073088A84609A36859D777FDA74C</td>\n",
       "      <td>كالا پخش عصر ايلام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D14E57BFCC2A46438127DB0E9D44E53D</td>\n",
       "      <td>تك ناهيد آدان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1F602F123D314279816445A72D249AE8</td>\n",
       "      <td>آراد پارس پويا شمال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DF530F7C9404386B1048F885A9F3CEF</td>\n",
       "      <td>شفق الكتريك هزاره سوم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D9A3EB25A9804B679DF5DD3BE7E212E0</td>\n",
       "      <td>امامزاده بي بي بانو روستاي بيان(قير)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                                  name\n",
       "0  6C08073088A84609A36859D777FDA74C                    كالا پخش عصر ايلام\n",
       "1  D14E57BFCC2A46438127DB0E9D44E53D                         تك ناهيد آدان\n",
       "2  1F602F123D314279816445A72D249AE8                   آراد پارس پويا شمال\n",
       "3  1DF530F7C9404386B1048F885A9F3CEF                 شفق الكتريك هزاره سوم\n",
       "4  D9A3EB25A9804B679DF5DD3BE7E212E0  امامزاده بي بي بانو روستاي بيان(قير)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data_sample.csv', header=None, names=['id', 'name'])\n",
    "data = data.drop(data.index[0])\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de122c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_names = data['name'].apply(preprocess_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54907653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5ae007e141444987519719aa489144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Mas\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Inspiron 5584\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e2735a0ca842c7bb03d89a31f83a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eb770f3a-2460-4988-a3d7-0e1f1e1fec5d)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./README.md\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c04eb1815e490f81f5cd276a3d8e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 35180696-b0c7-4a21-8c60-bb2efffd007a)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2979fd64f06e4883ba28fbe372660041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6022a771-cba1-4c25-ad1b-7aeb03f41b3e)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa00fe32268842c9819a92984b219720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2653c47514650a986aa08a328eb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: eb46b773-8470-435f-8a44-e3ab6ce1b9bf)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9288b27fc9c46138d41ce009bbe527d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0106b97328494b825e601765e118d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ca299cc27b41689c941a3c64e1c162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa21d0201f4405a80047555e027363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0a0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(name, registered_names):\n",
    "    return name in registered_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af473b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subsequence(name, registered_names):\n",
    "    name_tokens = set(name.split())\n",
    "    for reg in registered_names:\n",
    "        reg_tokens = set(reg.split())\n",
    "        if name_tokens.issubset(reg_tokens) or reg_tokens.issubset(name_tokens):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f789d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_permutation(name, registered_names):\n",
    "    name_tokens = sorted(name.split())\n",
    "    for reg in registered_names:\n",
    "        if name_tokens == sorted(reg.split()):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f07710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fuzzy_match(name, registered_names, threshold=85):\n",
    "    for reg in registered_names:\n",
    "        score = fuzz.token_sort_ratio(name, reg)\n",
    "        if score >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ba0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_semantic_similar(name, registered_names, threshold=0.85):\n",
    "    name_vec = model.encode([name])[0]\n",
    "    reg_vecs = model.encode(registered_names)\n",
    "    \n",
    "    for vec in reg_vecs:\n",
    "        sim = np.dot(name_vec, vec) / (np.linalg.norm(name_vec) * np.linalg.norm(vec))\n",
    "        if sim >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4026cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name_validity(name, registered_names):\n",
    "    if exact_match(name, registered_names):\n",
    "        return False, \"اسم دقیقا ثبت شده است\"\n",
    "    if is_subsequence(name, registered_names):\n",
    "        return False, \"اسم زیرمجموعه اسم ثبت شده است\"\n",
    "    if is_permutation(name, registered_names):\n",
    "        return False, \"اسم جایگشت اسم ثبت شده است\"\n",
    "    if is_fuzzy_match(name, registered_names):\n",
    "        return False, \"اسم مشابه اسم ثبت شده است (تغییر جزئی یا جمع/مفرد)\"\n",
    "    if is_semantic_similar(name, registered_names):\n",
    "        return False, \"اسم از نظر معنایی مشابه است\"\n",
    "    return True, \"اسم قابل ثبت است\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2cc0ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "صنایع میهن -> False - اسم از نظر معنایی مشابه است\n",
      "مهندسی هوشمند روزآمد تهران -> True - اسم قابل ثبت است\n",
      "صنایع غذای میهن -> False - اسم از نظر معنایی مشابه است\n",
      "تاجر آرمان -> False - اسم از نظر معنایی مشابه است\n",
      "فن‌آوری نوین پارس -> False - اسم از نظر معنایی مشابه است\n"
     ]
    }
   ],
   "source": [
    "test_names = [\n",
    "    \"صنایع میهن\",           \n",
    "    \"مهندسی هوشمند روزآمد تهران\",  \n",
    "    \"صنایع غذای میهن\",      \n",
    "    \"تاجر آرمان\",           \n",
    "    \"فن‌آوری نوین پارس\"     \n",
    "]\n",
    "\n",
    "for name in test_names:\n",
    "    valid, reason = check_name_validity(name, registered_names)\n",
    "    print(name, \"->\", valid, \"-\", reason)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

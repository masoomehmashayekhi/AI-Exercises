{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14029575,"sourceType":"datasetVersion","datasetId":8933858}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets scikit-learn torch shekar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:40:11.578075Z","iopub.execute_input":"2025-12-06T15:40:11.578637Z","iopub.status.idle":"2025-12-06T15:41:32.865347Z","shell.execute_reply.started":"2025-12-06T15:40:11.578615Z","shell.execute_reply":"2025-12-06T15:41:32.864505Z"},"editable":false},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/dataset/final_generated_pairs.csv', header=None,names=['name1', 'name2','label'])\ndf = df.drop(df.index[0])\ndf = df.reset_index(drop=True)\ndf.head()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PERSIAN_STOPWORDS = {\n    \"شرکت\",\"موسسه\",\"گروه\",\"صنعت\",\"صنایع\",\"توسعه\",\"مهندسی\",\"فناوری\",\"نوین\",\n    \"تک\",\"ارتباط\",\"مبین\",\"پیشرفته\",\"گسترش\",\"مرکز\",\"هولدینگ\",\n    \"مدرن\",\"نو\",\"جدید\",\"پژوهش\",\"کاربردی\",\"راهکار\",\"راه\",\"راه‌حل\",\n    \"اندیشه\",\"سامانه\",\"خدمات\",\"تجارت\",\"تجاری\",\"بازرگانی\",\"کو\",\"ایران\",\n   \"و\", \"در\", \"با\", \"از\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:40.083687Z","iopub.execute_input":"2025-12-06T15:45:40.084442Z","iopub.status.idle":"2025-12-06T15:45:40.088682Z","shell.execute_reply.started":"2025-12-06T15:45:40.084413Z","shell.execute_reply":"2025-12-06T15:45:40.087806Z"},"editable":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from shekar import Normalizer, Stemmer, WordTokenizer, Lemmatizer\nimport re\n\nnormalizer = Normalizer()\nlemmatizer = Lemmatizer()\ntokenizer = WordTokenizer()\n\ndef preprocess_and_stem(text):\n    text = normalizer.normalize(text)\n    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n    text = text.replace(\"\\u200c\", \"\")\n    text = str(clean(text,\n                           clean_all= False  ,\n                           extra_spaces=True ,\n                           numbers=True ,\n                           punct=True\n                           ))\n\n    tokens = list(tokenizer(text))\n\n    stems =  [lemmatizer(t) for t in tokens if t not in PERSIAN_STOPWORDS]\n    return \" \".join(stems)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:45.363134Z","iopub.execute_input":"2025-12-06T15:45:45.363850Z","iopub.status.idle":"2025-12-06T15:45:46.250487Z","shell.execute_reply.started":"2025-12-06T15:45:45.363825Z","shell.execute_reply":"2025-12-06T15:45:46.249613Z"},"editable":false},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df[\"label\"] = df[\"label\"].map({\n    \"1\": 1,\n    \"0\": 0\n}).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:49.841916Z","iopub.execute_input":"2025-12-06T15:45:49.842667Z","iopub.status.idle":"2025-12-06T15:45:49.856098Z","shell.execute_reply.started":"2025-12-06T15:45:49.842640Z","shell.execute_reply":"2025-12-06T15:45:49.855326Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n \ntrain_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n\nprint(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:52.460515Z","iopub.execute_input":"2025-12-06T15:45:52.461167Z","iopub.status.idle":"2025-12-06T15:45:53.112681Z","shell.execute_reply.started":"2025-12-06T15:45:52.461142Z","shell.execute_reply":"2025-12-06T15:45:53.111855Z"},"editable":false},"outputs":[{"name":"stdout","text":"Train size: 114437, Validation size: 24522, Test size: 24523\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:56.081012Z","iopub.execute_input":"2025-12-06T15:45:56.081470Z","iopub.status.idle":"2025-12-06T15:46:00.925976Z","shell.execute_reply.started":"2025-12-06T15:45:56.081446Z","shell.execute_reply":"2025-12-06T15:46:00.925355Z"},"editable":false},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"PartAI/TookaBERT-Base\"   \ntokenizer = AutoTokenizer.from_pretrained(model_name)\n \ndef tokenize_function(example):\n    return tokenizer(example['name1'], example['name2'], truncation=True, max_length=128)\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nval_dataset = val_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-06T16:13:02.727Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import DataCollatorWithPadding\n\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\nval_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:46:50.676978Z","iopub.execute_input":"2025-12-06T15:46:50.677278Z","iopub.status.idle":"2025-12-06T15:47:11.202695Z","shell.execute_reply.started":"2025-12-06T15:46:50.677256Z","shell.execute_reply":"2025-12-06T15:47:11.202084Z"},"editable":false},"outputs":[{"name":"stderr","text":"2025-12-06 15:46:52.290955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765036012.491763      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765036012.554190      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nnum_labels = 2  \nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:47:15.354598Z","iopub.execute_input":"2025-12-06T15:47:15.356002Z","iopub.status.idle":"2025-12-06T15:47:22.092696Z","shell.execute_reply.started":"2025-12-06T15:47:15.355973Z","shell.execute_reply":"2025-12-06T15:47:22.091875Z"},"editable":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64624def51a48d6a18a4d2beb969b68"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2b7d869133a4a91a0f8105e0461b8e4"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ntraining_args = TrainingArguments(\n    output_dir=\"./tookabert-finetuned\",\n    logging_steps=100,   \n    save_steps=500, \n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs', \n    metric_for_best_model=\"accuracy\",\n    fp16=True\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n    acc = accuracy_score(labels, predictions)\n    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:47:32.724350Z","iopub.execute_input":"2025-12-06T15:47:32.724672Z","iopub.status.idle":"2025-12-06T15:47:37.880233Z","shell.execute_reply.started":"2025-12-06T15:47:32.724650Z","shell.execute_reply":"2025-12-06T15:47:37.879601Z"},"editable":false},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/947905691.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(\"PyTorch version:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device name:\", torch.cuda.get_device_name(0))\n    print(\"Device count:\", torch.cuda.device_count())\nelse:\n    print(\"Running on CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:47:42.642094Z","iopub.execute_input":"2025-12-06T15:47:42.642666Z","iopub.status.idle":"2025-12-06T15:47:42.647398Z","shell.execute_reply.started":"2025-12-06T15:47:42.642641Z","shell.execute_reply":"2025-12-06T15:47:42.646551Z"},"editable":false},"outputs":[{"name":"stdout","text":"PyTorch version: 2.6.0+cu124\nCUDA available: True\nDevice name: Tesla T4\nDevice count: 2\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install -q wandb\n\nimport wandb\nwandb.init(project=\"tookabert-finetune\", name=\"run1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:47:47.264276Z","iopub.execute_input":"2025-12-06T15:47:47.264895Z","execution_failed":"2025-12-06T16:13:02.726Z"},"editable":false},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-06T15:37:55.901Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = trainer.evaluate(test_dataset)\nprint(results)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-06T15:37:55.901Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"./tookabert-finetuned\")\ntokenizer.save_pretrained(\"./tookabert-finetuned\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-06T15:37:55.901Z"},"editable":false},"outputs":[],"execution_count":null}]}
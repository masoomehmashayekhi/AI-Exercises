{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbd147c",
   "metadata": {},
   "source": [
    "\n",
    "# ๐ง ฺฉุงุฑฺฏุงู ุชุญูู ูุธุฑุงุช ูุงุฑุณ ุฏุฌโฺฉุงูุง (Persian NLP 2025)\n",
    "\n",
    "ุฏุฑ ุงู ููุชโุจูฺฉุ ฺฏุงูโุจูโฺฏุงู ุฑู ุฏุชุงุณุช ูุธุฑุงุช ุฏุฌโฺฉุงูุง ฺฉุงุฑ ูโฺฉูู ู ุงู ูุฑุงุญู ุฑุง ุงูุฌุงู ูโุฏูู:\n",
    "\n",
    "1. ุขุดูุง ุจุง ุฏุชุงุณุช ู ฺุงูุดโูุง ูุชูู ูุงุฑุณ  \n",
    "2. ูพุงฺฉโุณุงุฒ ู ูุฑูุงูโุณุงุฒ ูุชู ูุงุฑุณ  \n",
    "3. ุฑูุด ฺฉูุงุณฺฉ: **TF-IDF + ูุฏูโูุง ุงุฏฺฏุฑ ูุงุดู**  \n",
    "4. ุฑูุด ูุฏุฑู: **Embedding ุจุง BGE-M3**  \n",
    "5. ููุงุณู ุนููฺฉุฑุฏ TF-IDF ู Embedding  \n",
    "6. ููุงุด ูุถุง ูุนูุง ุจุง UMAP  \n",
    "7. ุงุณุชูุงุฏูโ ููุฏูุงุช ุงุฒ LLMูุง ุจุฑุง ุชุญูู ุงุญุณุงุณ ู ุฎูุงุตูโุณุงุฒ  \n",
    "8. ุชูุฑู ูพุงุงู: ุชุญูู ฺฉุงูู ูุธุฑุงุช ฺฉ ูุญุตูู\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8364be",
   "metadata": {},
   "source": [
    "\n",
    "## 1๏ธโฃ ูุตุจ ฺฉุชุงุจุฎุงููโูุง ููุฑุฏูุงุฒ\n",
    "\n",
    "ุฏุฑ ุงู ุจุฎุดุ ฺฉุชุงุจุฎุงููโูุง ุงุตู ููุฑุฏ ุงุณุชูุงุฏู ุฑุง ูุตุจ ูโฺฉูู:\n",
    "\n",
    "- `pandas`, `numpy` ุจุฑุง ฺฉุงุฑ ุจุง ุฏุงุฏูโูุง  \n",
    "- `scikit-learn` ุจุฑุง TF-IDF ู ูุฏูโูุง ุงุฏฺฏุฑ ูุงุดู  \n",
    "- `matplotlib` ุจุฑุง ุฑุณู ูููุฏุงุฑูุง  \n",
    "- `sentence-transformers` ุจุฑุง ุณุงุฎุช embedding (ูุฏู BGE-M3)  \n",
    "- `umap-learn` ุจุฑุง ฺฉุงูุด ุจูุนุฏ ู ููุงุด ุจุตุฑ embeddingูุง  \n",
    "\n",
    "> ูฺฉุชู: ูุตุจ ูพฺฉุฌโูุง ุฏุฑ Colab ููฺฉู ุงุณุช ฺูุฏ ุฏููู ุฒูุงู ุจุจุฑุฏ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd550f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ูุตุจ ูพฺฉุฌโูุง ุงุตู (ุฏุฑ ุตูุฑุช ูุงุฒ)\n",
    "!pip install -q pandas numpy scikit-learn matplotlib\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q umap-learn\n",
    "\n",
    "# ฺฉุชุงุจุฎุงููโูุง ุงุฎุชุงุฑ (ุฏุฑ ุตูุฑุช ูุงุฒ uncomment ฺฉูุฏ)\n",
    "# !pip install -q bertopic[all]\n",
    "# !pip install -q faiss-cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6b1f5",
   "metadata": {},
   "source": [
    "\n",
    "## 2๏ธโฃ ุจุงุฑฺฏุฐุงุฑ ุฏุชุงุณุช ูุธุฑุงุช ุฏุฌโฺฉุงูุง\n",
    "\n",
    "ุฏุฑ ุงู ฺฉุงุฑฺฏุงู ุงุฒ ุฏุชุงุณุช ุขูุงุฏูโ ูุธุฑุงุช ูุงุฑุณ ุฏุฌโฺฉุงูุง ุงุณุชูุงุฏู ูโฺฉูู.\n",
    "\n",
    "- ุงฺฏุฑ ุฏุชุงุณุช ุฑุง ุงุฒ Kaggle ุฏุงูููุฏ ฺฉุฑุฏูโุงุฏุ ุขู ุฑุง ุฏุฑ ูุณุฑ ููุงุณุจ ูุฑุงุฑ ุฏูุฏ.  \n",
    "- ุดฺฉู ุฏุชุงุณุช ูุฑุถ:  \n",
    "  - `Text` : ูุชู ฺฉุงูู ูุธุฑ ูุดุชุฑ  \n",
    "  - `Score`: ุงูุชุงุฒ ุนุฏุฏ (ฑ ุชุง ต)  \n",
    "  - `Suggestion`: ุขุง ฺฉุงุฑุจุฑ ุฎุฑุฏ ุฑุง ูพุดููุงุฏ ูโฺฉูุฏ ุง ูู (ุงุฎุชุงุฑ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fa8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ุงฺฏุฑ ูุงู ุฑุง ุฏุฑ Colab ุขูพููุฏ ฺฉุฑุฏูโุงุฏุ ูุงู ูุงู ุฑุง ุงูุฌุง ุจฺฏุฐุงุฑุฏ\n",
    "DATA_PATH = \"data.csv\"  # ุง ูุงู ูุงู ฺฉู ุงุฒ Kaggle ฺฏุฑูุชูโุงุฏ\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c92cf5",
   "metadata": {},
   "source": [
    "\n",
    "### ูฺฏุงู ุณุฑุน ุจู ุฏุงุฏูโูุง\n",
    "\n",
    "ุชูุฒุน ุงูุชุงุฒูุง ุฑุง ุจุฑุฑุณ ูโฺฉูู ุชุง ุจุจูู ุฏุงุฏูโูุง ูุชูุงุฒู ูุณุชูุฏ ุง ูู.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace27feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b5d43",
   "metadata": {},
   "source": [
    "\n",
    "## 3๏ธโฃ ุชุนุฑู ุจุฑฺุณุจ ุงุญุณุงุณ (Sentiment Label)\n",
    "\n",
    "ุจุฑุง ุณุงุฏูโุณุงุฒ ูุณุฆููุ ุงูุชุงุฒูุง ุฑุง ุจู ุณู ฺฉูุงุณ ุชุจุฏู ูโฺฉูู:\n",
    "\n",
    "- **ฑ ู ฒ โ ููู (negative)**  \n",
    "- **ณ โ ุฎูุซ (neutral)** (ุฏุฑ ุตูุฑุช ฺฉู ุจูุฏูุ ูโุชูุงูู ุญุฐู ฺฉูู)  \n",
    "- **ด ู ต โ ูุซุจุช (positive)**  \n",
    "\n",
    "ุฏุฑ ุงู ููุชโุจูฺฉ ุจุฑุง ุณุงุฏฺฏุ ููุท ุฏู ฺฉูุงุณ ูุซุจุช/ููู ุฑุง ูฺฏู ูโุฏุงุฑู ู ฺฉูุงุณ ุฎูุซ ุฑุง ุญุฐู ูโฺฉูู.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_label(score):\n",
    "    if score <= 2:\n",
    "        return \"negative\"\n",
    "    elif score >= 4:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df['label'] = df['Score'].apply(score_to_label)\n",
    "\n",
    "# ุญุฐู ูุธุฑุงุช ุฎูุซ (ุฏุฑ ุตูุฑุช ฺฉู ุจูุฏู)\n",
    "df = df[df['label'] != 'neutral'].reset_index(drop=True)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8572e9",
   "metadata": {},
   "source": [
    "\n",
    "## 4๏ธโฃ ูพุงฺฉโุณุงุฒ ู ูุฑูุงูโุณุงุฒ ูุชู ูุงุฑุณ\n",
    "\n",
    "ุฏุฑ ูุชูู ูุงุฑุณ ูุดฺฉูุงุช ุฑุงุฌ ุฏุงุฑู:\n",
    "\n",
    "- ูุฎููุท ุดุฏู ุญุฑูู ุนุฑุจ ู ูุงุฑุณ (`ู` / ``ุ `ู` / `ฺฉ`)  \n",
    "- ูุฌูุฏ ุงููุฌโูุงุ URLูุงุ @mentionูุง ู โฆ  \n",
    "- ุนูุงุฆู ูฺฏุงุฑุด ุงุถุงู  \n",
    "- ูุงุตููโูุง ุชฺฉุฑุงุฑ  \n",
    "- ุงุนุฏุงุฏ ูุงุฑุณ ู ุงูฺฏูุณ  \n",
    "\n",
    "ุฏุฑ ุงู ุจุฎุด ฺฉ ุชุงุจุน `clean_persian_text` ูพุงุฏูโุณุงุฒ ูโฺฉูู ฺฉู ฺฉุงุฑูุง ุฒุฑ ุฑุง ุงูุฌุงู ูโุฏูุฏ:\n",
    "\n",
    "1. ฺฉููุงุฎุชโุณุงุฒ ุญุฑูู (`ู`โ`` ู `ู`โ`ฺฉ`)  \n",
    "2. ุญุฐู URLุ ุงููุ @mention ู ูุดุชฺฏ  \n",
    "3. ุญุฐู ุงููุฌโูุง ู ฺฉุงุฑุงฺฉุชุฑูุง ุบุฑุญุฑู ุบุฑุถุฑูุฑ  \n",
    "4. ุญุฐู ุนูุงุฆู ูฺฏุงุฑุด ู ุชุจุฏู ุขููุง ุจู ูุงุตูู  \n",
    "5. ุญุฐู ูุงุตููโูุง ุชฺฉุฑุงุฑ ู strip ฺฉุฑุฏู ูุชู  \n",
    "6. ุชุจุฏู ููู ฺุฒ ุจู ุญุฑูู ฺฉูฺฺฉ (ุฏุฑ ูุงุฑุณ ุชุฃุซุฑ ุฒุงุฏ ูุฏุงุฑุฏ ุงูุง ุจุฑุง ฺฉุฏุณุช ููุฏ ุงุณุช)\n",
    "\n",
    "> ูฺฉุชู: ุงฺฏุฑ ุฎูุงุณุชุฏ ูโุชูุงูุฏ ุฑู ุงู ูุชูโูุงุ Stemming ุง Lemmatization ูุงุฑุณ (ูุซูุงู ุจุง `hazm` ุง `parsivar`) ูุฒ ุงูุฌุงู ุฏูุฏ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72315b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ุงูฺฏู ุงููุฌโูุง (ุณุงุฏู)\n",
    "emoji_pattern = re.compile(\"\"\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "\"]+\"\"\", flags=re.UNICODE)\n",
    "\n",
    "def normalize_arabic_chars(text: str) -> str:\n",
    "    # ู/ ู ู/ฺฉ\n",
    "    text = text.replace('ู', '').replace('ู', '')\n",
    "    text = text.replace('ู', 'ฺฉ')\n",
    "    return text\n",
    "\n",
    "def convert_persian_digits(text: str) -> str:\n",
    "    persian_digits = 'ฐฑฒณดตถทธน'\n",
    "    english_digits = '0123456789'\n",
    "    trans_table = str.maketrans(''.join(persian_digits), ''.join(english_digits))\n",
    "    return text.translate(trans_table)\n",
    "\n",
    "def clean_persian_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = normalize_arabic_chars(text)\n",
    "    text = convert_persian_digits(text)\n",
    "\n",
    "    # ุญุฐู URLูุง\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
    "\n",
    "    # ุญุฐู ุงูู\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "\n",
    "    # ุญุฐู @mention ู ูุดุชฺฏ\n",
    "    text = re.sub(r'[@#]\\S+', ' ', text)\n",
    "\n",
    "    # ุญุฐู ุงููุฌโูุง\n",
    "    text = emoji_pattern.sub(' ', text)\n",
    "\n",
    "    # ุญุฐู ูุฑฺุฒ ุจู ุฌุฒ ุญุฑูู ู ุงุนุฏุงุฏ ู ูุงุตูู\n",
    "    text = re.sub(r'[^ฐ-น0-9ุข-ุฆุกฺฺฺฏฑฒณดตถทธน\\s]', ' ', text)\n",
    "\n",
    "    # ุชุจุฏู ฺูุฏ ูุงุตูู ุจู ฺฉ\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # ฺฉูฺฺฉโุณุงุฒ (ุฏุฑ ูุงุฑุณ ุญุณุงุณุช ฺฉูุชุฑ ุฏุงุฑุฏ)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['Text'].astype(str).apply(clean_persian_text)\n",
    "df[['Text', 'clean_text']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515468c3",
   "metadata": {},
   "source": [
    "\n",
    "## 5๏ธโฃ ุฑูุด ฺฉูุงุณฺฉ: TF-IDF + ูุฏูโูุง ุงุฏฺฏุฑ ูุงุดู\n",
    "\n",
    "ุฏุฑ ุงู ุจุฎุด:\n",
    "\n",
    "1. ูุชูโูุง `clean_text` ุฑุง ุจุง `TfidfVectorizer` ุจู ุจุฑุฏุงุฑ ุชุจุฏู ูโฺฉูู.  \n",
    "2. ุฏุงุฏูโูุง ุฑุง ุจู train/test ุชูุณู ูโฺฉูู.  \n",
    "3. ฺูุฏ ูุฏู ุฑุง ุฑู TF-IDF ุขููุฒุด ูโุฏูู:\n",
    "   - Logistic Regression  \n",
    "   - Linear SVM  \n",
    "   - Random Forest  \n",
    "4. ูุนุงุฑูุง ุงุฑุฒุงุจ (Accuracyุ Precisionุ Recallุ F1) ู Confusion Matrix ุฑุง ุจุฑุฑุณ ูโฺฉูู.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ุณุงุฎุช TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "y = df['label']\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02371324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tfidf_results = []\n",
    "\n",
    "def evaluate_model_tfidf(name, model):\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    preds = model.predict(X_test_tfidf)\n",
    "\n",
    "    acc = accuracy_score(y_test_tfidf, preds)\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        y_test_tfidf, preds, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    tfidf_results.append([name, acc, p, r, f])\n",
    "    print(f\"===== {name} (TF-IDF) =====\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {p:.4f} | Recall: {r:.4f} | F1: {f:.4f}\")\n",
    "    print()\n",
    "    print(classification_report(y_test_tfidf, preds))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    labels = sorted(y.unique())\n",
    "    cm = confusion_matrix(y_test_tfidf, preds, labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix - {name} (TF-IDF)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ุงุฌุฑุง ูุฏูโูุง\n",
    "lr_t = LogisticRegression(max_iter=3000)\n",
    "evaluate_model_tfidf(\"Logistic Regression\", lr_t)\n",
    "\n",
    "svm_t = LinearSVC()\n",
    "evaluate_model_tfidf(\"Linear SVM\", svm_t)\n",
    "\n",
    "rf_t = RandomForestClassifier(n_estimators=300)\n",
    "evaluate_model_tfidf(\"Random Forest\", rf_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9aad9a",
   "metadata": {},
   "source": [
    "\n",
    "## 6๏ธโฃ ุฑูุด ูุฏุฑู: Embedding ุจุง BGE-M3\n",
    "\n",
    "ุฏุฑ ุฑูุดโูุง ูุฏุฑู NLP ุจู ุฌุง ุดูุงุฑุด ฺฉููุงุชุ ูุฑ ุฌููู/ูุธุฑ ุฑุง ุจู ฺฉ **ุจุฑุฏุงุฑ ูุนูุง** ุฏุฑ ูุถุง ุจุง ุจูุนุฏ ุจุงูุง ุชุจุฏู ูโฺฉูู.\n",
    "\n",
    "ุฏุฑ ุงู ุจุฎุด ุงุฒ ูุฏู **BGE-M3** ุงุณุชูุงุฏู ูโฺฉูู ฺฉู:\n",
    "\n",
    "- ฺูุฏุฒุจุงูู ุงุณุช (ุงุฒ ุฌููู ูุงุฑุณ)  \n",
    "- ุจุฑุง ุจุงุฒุงุจ ูุนูุง (Semantic Search) ู Classification ุนุงู ุนูู ูโฺฉูุฏ  \n",
    "- ูุฑ ูุชู ุฑุง ุจู ฺฉ ุจุฑุฏุงุฑ ฑฐฒดุจูุนุฏ ุชุจุฏู ูโฺฉูุฏ\n",
    "\n",
    "ูุฑุงุญู:\n",
    "\n",
    "1. ููุฏ ฺฉุฑุฏู ูุฏู `BAAI/bge-m3` ุจุง `sentence-transformers`  \n",
    "2. ุชุจุฏู ูููโ `clean_text`ูุง ุจู embedding  \n",
    "3. ุขููุฒุด ููุงู ูุฏูโูุง ูุจู (LRุ SVMุ RFุ XGBoostุ LightGBMุ KNNุ MLP) ุฑู embeddingูุง  \n",
    "4. ููุงุณู ูุชุงุฌ ุจุง TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb28cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Loading BGE-M3 model...\")\n",
    "emb_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "embeddings = emb_model.encode(\n",
    "    df['clean_text'].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ed268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = embeddings\n",
    "y = df['label']\n",
    "\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "emb_results = []\n",
    "\n",
    "def evaluate_model_emb(name, model, encoded=False):\n",
    "    if encoded:\n",
    "        le = LabelEncoder()\n",
    "        y_enc = le.fit_transform(y)\n",
    "        X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(\n",
    "            X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    "        )\n",
    "        model.fit(X_train_e, y_train_e)\n",
    "        preds = model.predict(X_test_e)\n",
    "        true_y = y_test_e\n",
    "    else:\n",
    "        model.fit(X_train_emb, y_train_emb)\n",
    "        preds = model.predict(X_test_emb)\n",
    "        true_y = y_test_emb\n",
    "\n",
    "    acc = accuracy_score(true_y, preds)\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        true_y, preds, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    emb_results.append([name, acc, p, r, f])\n",
    "\n",
    "    print(f\"===== {name} (Embedding) =====\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {p:.4f} | Recall: {r:.4f} | F1: {f:.4f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# ูุฏูโูุง ฺฉูุงุณฺฉ ุฑู Embedding\n",
    "evaluate_model_emb(\"Logistic Regression\", LogisticRegression(max_iter=3000))\n",
    "evaluate_model_emb(\"Linear SVM\", LinearSVC())\n",
    "evaluate_model_emb(\"Random Forest\", RandomForestClassifier(n_estimators=300))\n",
    "evaluate_model_emb(\"KNN\", KNeighborsClassifier(n_neighbors=7))\n",
    "evaluate_model_emb(\"MLP Neural Network\", MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500))\n",
    "\n",
    "# ูุฏูโูุง ฺฏุฑุงุฏุงูโุจูุณูฺฏ ุจุง ูุจู ุนุฏุฏ\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "evaluate_model_emb(\"XGBoost\", xgb, encoded=True)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.1)\n",
    "evaluate_model_emb(\"LightGBM\", lgbm, encoded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b033bd",
   "metadata": {},
   "source": [
    "\n",
    "## 7๏ธโฃ ููุงุณูโ TF-IDF ู Embedding\n",
    "\n",
    "ุฏุฑ ุงู ุจุฎุด ูุชุงุฌ ูุฏูโูุง ุฑุง ุฏุฑ ุฏู ุญุงูุช ููุงุณู ูโฺฉูู:\n",
    "\n",
    "- ููุงุด ุฌุฏูู  \n",
    "- ููุงุด ูููุฏุงุฑ (ูููุฏุงุฑ ูููโุง F1-score)\n",
    "\n",
    "ูุฏู: ูุดุงู ุฏูู ฺฉู Embedding ูุนูููุงู:\n",
    "- ุฏูุช ู F1 ุจุงูุงุชุฑ ูโุฏูุฏ  \n",
    "- ุจุฑุง ฺฉุงุฑูุง ุจุนุฏ ูุซู Semantic Search ู RAG ูุงุจู ุงุณุชูุงุฏู ุงุณุช  \n",
    "ุฏุฑ ุญุงู ฺฉู TF-IDF ุจุดุชุฑ ุจุฑุง ูุณู ูุฏูโุชุฑ NLP ููุงุณุจ ุงุณุช.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_results, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "tfidf_df[\"Representation\"] = \"TF-IDF\"\n",
    "\n",
    "emb_df = pd.DataFrame(emb_results, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "emb_df[\"Representation\"] = \"Embedding\"\n",
    "\n",
    "compare_df = pd.concat([tfidf_df, emb_df], ignore_index=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pivot = compare_df.pivot(index=\"Model\", columns=\"Representation\", values=\"F1\")\n",
    "compare_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3875ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pivot.plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"ููุงุณู F1 ูุฏูโูุง: TF-IDF vs Embedding\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d488598",
   "metadata": {},
   "source": [
    "\n",
    "## 8๏ธโฃ ููุงุด ุจุตุฑ ูุถุง ูุนูุง ุจุง UMAP\n",
    "\n",
    "ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ Embeddingูุงุ ุขููุง ุฑุง ุจุง UMAP ุงุฒ ฑฐฒด ุจูุนุฏ ุจู ฒ ุจูุนุฏ ฺฉุงูุด ูโุฏูู ู:\n",
    "\n",
    "- ูุฑ ููุทู = ฺฉ ูุธุฑ ูุดุชุฑ  \n",
    "- ุฑูฺฏ = ุจุฑฺุณุจ ุงุญุณุงุณ (ูุซุจุช / ููู)\n",
    "\n",
    "ุงู Visualization ฺฉูฺฉ ูโฺฉูุฏ:\n",
    "\n",
    "- ุฎูุดูโุจูุฏ ูุนูุง ูุธุฑุงุช ุฑุง ุจุจูู  \n",
    "- ุฌุฏุง ฺฉูุงุณโูุง ุฑุง ุฏุฑ ูุถุง embedding ูุดุงูุฏู ฺฉูู\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbeceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "umap_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "df['umap_x'] = umap_2d[:,0]\n",
    "df['umap_y'] = umap_2d[:,1]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for label, color in zip(['positive','negative'], ['tab:blue','tab:orange']):\n",
    "    subset = df[df['label'] == label]\n",
    "    plt.scatter(subset['umap_x'], subset['umap_y'], s=10, label=label)\n",
    "plt.legend()\n",
    "plt.title(\"UMAP Visualization of Persian Comment Embeddings\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a2eaa",
   "metadata": {},
   "source": [
    "\n",
    "## 9๏ธโฃ ุงุณุชูุงุฏูโ ููุฏูุงุช ุงุฒ LLMูุง (ุฎูุงุตูโุณุงุฒ ู ุชุญูู ุงุญุณุงุณ)\n",
    "\n",
    "ุฏุฑ ฺฉูุงุฑ ุฑูฺฉุฑุฏ ฺฉูุงุณฺฉ (ML + Embedding)ุ ูโุชูุงูู ุงุฒ LLMูุง ูุฒ ุงุณุชูุงุฏู ฺฉูู:\n",
    "\n",
    "**ฺฉุงุฑุจุฑุฏูุง:**\n",
    "\n",
    "- ุฎูุงุตูโุณุงุฒ ฺูุฏ ูุธุฑ ูุดุชุฑ  \n",
    "- ุงุณุชุฎุฑุงุฌ ูฺฉุงุช ูุซุจุช ู ููู  \n",
    "- ุชุญูู ุงุญุณุงุณ ุจู ุตูุฑุช Zero-shot ุง Few-shot  \n",
    "- ุชููุฏ ุชุญูู ูุฏุฑุช ุจู ุฒุจุงู ุทุจุน\n",
    "\n",
    "ุฏุฑ Colab ูโุชูุงูุฏ ุจุณุชู ุจู ุฏุณุชุฑุณ ุฎูุฏุชุงู ุงุฒ ฺฉ ุงุฒ ุงูโูุง ุงุณุชูุงุฏู ฺฉูุฏ:\n",
    "\n",
    "- ูุฏูโูุง `transformers` (ูุซูุงู Qwenุ Mistralุ LLaMA)  \n",
    "- APIูุง LLM (OpenAIุ ุณุงุฑ ุงุฑุงุฆูโุฏููุฏูโูุง)\n",
    "\n",
    "ุฏุฑ ุงูุฌุง ููุท ฺฉ ุดููุง ฺฉู ูโุฏูู ฺฉู ุดุฑฺฉุชโฺฉููุฏฺฏุงู ฺฉุงุฑฺฏุงู ุจุชูุงููุฏ ุจุนุฏุงู ุฎูุฏุดุงู ุชุณุช ฺฉููุฏ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ููููู ฺฉุฏ ููุงุด (Pseudo-code) ุจุฑุง ุงุณุชูุงุฏู ุงุฒ ฺฉ LLM HuggingFace\n",
    "# ุชูุฌู: ุจุฑุง ุงุฌุฑุง ุจุงุฏ ูุฏู ููุงุณุจ ุฑุง ุฌุงฺฏุฒู ฺฉูุฏ ู ููุงุจุน ูุงุฒู (GPU) ุฏุงุดุชู ุจุงุดุฏ.\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# model_name = \"Qwen/Qwen2.5-3B-Instruct\"  # ุจู ุนููุงู ูุซุงู\n",
    "# pipe = pipeline(\"text-generation\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "# sample_reviews = \"\\n\".join(df['clean_text'].sample(10).tolist())\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# ุงู ูุธุฑุงุช ูุดุชุฑุงู ุฑุง ุจุฎูุงู ู ููุงุฑุฏ ุฒุฑ ุฑุง ุจู ุฒุจุงู ูุงุฑุณ ู ุฎูุงุตู ุจููุณ:\n",
    "\n",
    "# - ุฎูุงุตู ฺฉู ุงุญุณุงุณ ูุดุชุฑุงู\n",
    "# - ูููโุชุฑู ููุงุท ูุซุจุช\n",
    "# - ูููโุชุฑู ููุงุท ููู\n",
    "# - ุณู ูพุดููุงุฏ ฺฉูุฏ ุจุฑุง ุจูุจูุฏ ูุญุตูู\n",
    "\n",
    "# ูุธุฑุงุช:\n",
    "# {sample_reviews}\n",
    "# \"\"\"\n",
    "\n",
    "# out = pipe(prompt, max_new_tokens=300)[0]['generated_text']\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7dc6a",
   "metadata": {},
   "source": [
    "\n",
    "## ๐ ุชูุฑู ูพุงุงู ฺฉุงุฑฺฏุงู\n",
    "\n",
    "ุจู ุนููุงู ุชูุฑู ููุงุ ูุฑุงุญู ุฒุฑ ุฑุง ุจุฑุง **ฺฉ ุฒุฑูุฌููุนู ุงุฒ ุฏุงุฏูโูุง (ูุซูุงู ฺฉ ูุญุตูู ุฎุงุต ุง ฺฉ ุฏุณุชูโ ุฎุงุต)** ุงูุฌุงู ุฏูุฏ:\n",
    "\n",
    "1. **ููุชุฑ ฺฉุฑุฏู ุฏุงุฏูโูุง**  \n",
    "   - ููุท ูุธุฑุงุช ูุฑุจูุท ุจู ฺฉ ูุญุตูู ูุดุฎุต ุง ฺฉ ุฏุณุชู ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ.\n",
    "\n",
    "2. **ุขููุฒุด ฺฉ ูุฏู ุงุญุณุงุณ ุณุงุฏู**  \n",
    "   - ุงุฒ Embedding (BGE-M3) ู Logistic Regression ุงุณุชูุงุฏู ฺฉูุฏ.  \n",
    "   - ุฏูุช ู F1 ุฑุง ฺฏุฒุงุฑุด ฺฉูุฏ.\n",
    "\n",
    "3. **Topic Modeling (ุงุฎุชุงุฑุ ุงฺฏุฑ BERTopic ูุตุจ ฺฉุฑุฏุฏ)**  \n",
    "   - ณ ุชุง ต ููุถูุน ุงุตู ุฏุฑ ูุธุฑุงุช ุฑุง ุงุณุชุฎุฑุงุฌ ฺฉูุฏ.  \n",
    "   - ุจุฑุง ูุฑ Topic ฺูุฏ ููููู ูุธุฑ ูุดุงู ุฏูุฏ.\n",
    "\n",
    "4. **Semantic Search (ุงุฎุชุงุฑ)**  \n",
    "   - ฺฉ ุณุคุงู ูุซู ยซูููโุชุฑู ุฏูู ูุงุฑุถุงุช ูุดุชุฑุงู ฺุณุชุยป ุชุนุฑู ฺฉูุฏ.  \n",
    "   - ูุฒุฏฺฉโุชุฑู ฑฐ ูุธุฑ ุฑุง ุจุง ูุงุตููโ Cosine ุฑู embeddingูุง ูพุฏุง ฺฉูุฏ.\n",
    "\n",
    "5. **ุชุญูู ูุฏุฑุช ููุง**  \n",
    "   - ุฏุฑ ูุงูุจ ตโท ุฎุทุ ฺฉ ฺฏุฒุงุฑุด ูุฏุฑุช ุจููุณุฏ ฺฉู ุดุงูู ููุงุฑุฏ ุฒุฑ ุจุงุดุฏ:\n",
    "     - ุฎูุงุตูโ ฺฉู ุงุญุณุงุณ ูุดุชุฑุงู  \n",
    "     - ูฺฉุงุช ูุซุจุช ุงุตู  \n",
    "     - ูุดฺฉูุงุช ุงุตู ูุทุฑุญ ุดุฏู ุชูุณุท ูุดุชุฑุงู  \n",
    "     - ูพุดููุงุฏูุง ฺฉูุฏ ุจุฑุง ูุงุญุฏูุง: ูุญุตููุ ูพุดุชุจุงูุ ูุฌุณุชฺฉ\n",
    "\n",
    "> ูพุดููุงุฏ: ุฎุฑูุฌ ุชูุฑู ุฑุง ุฏุฑ ฺฉ ุณููู Markdown ูุฑุชุจ ู ูุงุจู ุงุฑุงุฆู ุจููุณุฏ ุชุง ุจุชูุงูุฏ ุขู ุฑุง ุฏุฑ ุณุงุฒูุงู ุฎูุฏ ุจู ุงุดุชุฑุงฺฉ ุจฺฏุฐุงุฑุฏ.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

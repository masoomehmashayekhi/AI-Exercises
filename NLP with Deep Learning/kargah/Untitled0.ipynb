{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XgetCXaBYNHv"
      },
      "outputs": [],
      "source": [
        "!pip install -q numpy pandas scikit-learn matplotlib\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "xaC7JynIZDus",
        "outputId": "b8e40e4c-14ae-4609-bec4-10cd737a9821"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-898168759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_PATH='data.csv'\n",
        "\n",
        "df=pd.read_csv(DATA_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBSTjBN6Zm3E"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2yVGcewZuiQ"
      },
      "outputs": [],
      "source": [
        "df['Suggestion'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ROfwCvCaQFT"
      },
      "outputs": [],
      "source": [
        "def score_to_label(score):\n",
        "    if score <40:\n",
        "       return \"negetive\"\n",
        "    elif score>=60:\n",
        "       return \"positive\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "df['label']=df['Score'].apply(score_to_label)\n",
        "df = df[df['label'] != 'neutral'].reset_index(drop=True)\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhEdVxeib2L7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# الگوی اموجی‌ها (ساده)\n",
        "emoji_pattern = re.compile(\"\"\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "\"]+\"\"\", flags=re.UNICODE)\n",
        "\n",
        "def normalize_arabic_chars(text: str) -> str:\n",
        "    # ي/ی و ك/ک\n",
        "    text = text.replace('ي', 'ی').replace('ى', 'ی')\n",
        "    text = text.replace('ك', 'ک')\n",
        "    return text\n",
        "\n",
        "def convert_persian_digits(text: str) -> str:\n",
        "    persian_digits = '۰۱۲۳۴۵۶۷۸۹'\n",
        "    english_digits = '0123456789'\n",
        "    trans_table = str.maketrans(''.join(persian_digits), ''.join(english_digits))\n",
        "    return text.translate(trans_table)\n",
        "\n",
        "def clean_persian_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = normalize_arabic_chars(text)\n",
        "    text = convert_persian_digits(text)\n",
        "\n",
        "    # حذف URLها\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
        "\n",
        "    # حذف ایمیل\n",
        "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
        "\n",
        "    # حذف @mention و هشتگ\n",
        "    text = re.sub(r'[@#]\\S+', ' ', text)\n",
        "\n",
        "    # حذف اموجی‌ها\n",
        "    text = emoji_pattern.sub(' ', text)\n",
        "\n",
        "    # حذف هرچیزی به جز حروف و اعداد و فاصله\n",
        "    text = re.sub(r'[^۰-۹0-9آ-یئءچژگۀ۱۲۳۴۵۶۷۸۹\\s]', ' ', text)\n",
        "\n",
        "    # تبدیل چند فاصله به یکی\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # کوچک‌سازی (در فارسی حساسیت کمتری دارد)\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['Text'].astype(str).apply(clean_persian_text)\n",
        "df[['Text', 'clean_text']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iUojqr-clGl"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfidf_vectorixer= TfidfVectorizer(ngram_range=(1,2),\n",
        "                                  min_df=5,\n",
        "                                  max_df=0.9)\n",
        "\n",
        "y=df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], y, test_size=0.2,random_state=42, stratify=y)\n",
        "\n",
        "X_train = tfidf_vectorixer.fit_transform(X_train)\n",
        "X_test = tfidf_vectorixer.transform(X_test)\n",
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2QX3l7EfylZ"
      },
      "outputs": [],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmRXTl6xgJ3B"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "def accuracy(str,cl,X_test,y_test):\n",
        "  y_pred = cl.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "  # Precision\n",
        "  precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "  # Recall\n",
        "  recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "  # F1-score\n",
        "  f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "  # Confusion matrix\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # گزارش کامل\n",
        "  report = classification_report(y_test, y_pred)\n",
        "\n",
        "  print(f\"--------{str} scores-----\")\n",
        "  print(f\"-------------------------\")\n",
        "  print(\"Accuracy :\", accuracy)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"Recall   :\", recall)\n",
        "  print(\"F1-score :\", f1)\n",
        "  print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "  print(\"\\nClassification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hIkC1pf4vQB"
      },
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "cl= LogisticRegression(max_iter=3000)\n",
        "cl.fit(X_train,y_train)\n",
        "accuracy(\"LogisticRegression\",cl,X_test,y_test)\n",
        "\n",
        "svm= LinearSVC()\n",
        "svm.fit(X_train,y_train)\n",
        "accuracy(\"LinearSVC\",svm,X_test,y_test)\n",
        "\n",
        "rf= RandomForestClassifier(n_estimators=300)\n",
        "rf.fit(X_train,y_train)\n",
        "accuracy(\"RandomForestClassifier\",rf,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3_LU-OYwjKC"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "print(\"Loading BGE-M3 model...\")\n",
        "emb_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "embeddings = emb_model.encode(\n",
        "df['clean_text'].tolist(),\n",
        "batch_size=32,\n",
        "show_progress_bar=True\n",
        ")\n",
        "embeddings.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHEO4GMJy7Q6"
      },
      "outputs": [],
      "source": [
        "X_train_bge, X_test_bge, y_train_bge, y_test_bge = train_test_split(embeddings, y, test_size=0.2,random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "print(X_train_bge.shape)\n",
        "print(X_test_bge.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsWlr2Qik9My"
      },
      "outputs": [],
      "source": [
        "#BGE-M3\n",
        "clbge= LogisticRegression(max_iter=3000)\n",
        "clbge.fit(X_train_bge,y_train_bge)\n",
        "accuracy(\"LogisticRegression\", clbge, X_test_bge, y_test_bge)\n",
        "\n",
        "svmbge= LinearSVC()\n",
        "svmbge.fit(X_train_bge,y_train_bge)\n",
        "accuracy(\"LinearSVC\", svmbge, X_test_bge, y_test_bge)\n",
        "\n",
        "rfbge= RandomForestClassifier(n_estimators=300)\n",
        "rfbge.fit(X_train_bge, y_train_bge)\n",
        "accuracy(\"RandomForestClassifier\",rfbge, X_test_bge, y_test_bge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jfKvHa0suFc"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"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\",\n",
        ")\n",
        "batch_size = 100\n",
        "embeddings_list = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['clean_text'].iloc[i:i+batch_size].tolist()\n",
        "    resp = client.embeddings.create(\n",
        "        model=\"openai/text-embedding-3-small\",\n",
        "        input=batch_texts\n",
        "    )\n",
        "    embeddings_list.extend([d.embedding for d in resp.data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMepWOcUyqwa"
      },
      "outputs": [],
      "source": [
        "print(embeddings_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv6apLi407tR"
      },
      "outputs": [],
      "source": [
        "X_train_openai, X_test_openai, y_train_openai, y_test_openai = train_test_split(np.array(embeddings_list), y, test_size=0.2,random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "print(X_train_openai.shape)\n",
        "print(X_test_openai.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSzuNHC73osa"
      },
      "outputs": [],
      "source": [
        "X_train_openai[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XQOeDmts4Rd"
      },
      "outputs": [],
      "source": [
        "#openAI\n",
        "clopenai= LogisticRegression(max_iter=3000, class_weight='balanced')\n",
        "clopenai.fit(X_train_openai,y_train_openai)\n",
        "accuracy(\"LogisticRegression\", clopenai, X_test_openai, y_test_openai)\n",
        "\n",
        "svmopenai= LinearSVC()\n",
        "svmopenai.fit(X_train_openai,y_train_openai)\n",
        "accuracy(\"LinearSVC\", svmopenai, X_test_openai, y_test_openai)\n",
        "\n",
        "rfopenai= RandomForestClassifier(n_estimators=300)\n",
        "rfopenai.fit(X_train_openai,y_train_openai)\n",
        "accuracy(\"RandomForestClassifier\",rfopenai, X_test_openai, y_test_openai)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lEFXlvA5udi"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm  as lgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAkL57Zu-s_5"
      },
      "outputs": [],
      "source": [
        "#BGE-M3\n",
        "le = LabelEncoder()\n",
        "y_train_bge_enc = le.fit_transform(y_train_bge)\n",
        "y_test_bge_enc  = le.transform(y_test_bge)\n",
        "\n",
        "\n",
        "knnbge = KNeighborsClassifier(n_neighbors=5)\n",
        "knnbge.fit(X_train_bge,y_train_bge_enc)\n",
        "accuracy(\"KNeighborsClassifier\", knnbge, X_test_bge, y_test_bge_enc)\n",
        "\n",
        "\n",
        "mlpbge  = MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500, random_state=42)\n",
        "mlpbge .fit(X_train_bge,y_train_bge_enc)\n",
        "accuracy(\"MLPClassifier\", mlpbge , X_test_bge, y_test_bge_enc)\n",
        "\n",
        "\n",
        "xgbbge = XGBClassifier(n_estimators=300, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgbbge.fit(X_train_bge,y_train_bge_enc)\n",
        "accuracy(\"XGBClassifier\", xgbbge, X_test_bge, y_test_bge_enc)\n",
        "\n",
        "\n",
        "lgbmbge = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.05, max_depth=7, random_state=42)\n",
        "lgbmbge.fit(X_train_bge,y_train_bge_enc)\n",
        "accuracy(\"LGBMClassifier\", lgbmbge, X_test_bge, y_test_bge_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_f3h78cAzjz"
      },
      "outputs": [],
      "source": [
        "#OpenAI\n",
        "le = LabelEncoder()\n",
        "y_train_openai_enc = le.fit_transform(y_train_openai)\n",
        "y_test_openai_enc  = le.transform(y_test_openai)\n",
        "\n",
        "\n",
        "knnopenai = KNeighborsClassifier(n_neighbors=5)\n",
        "knnopenai.fit(X_train_openai,y_train_openai_enc)\n",
        "accuracy(\"KNeighborsClassifier\", knnopenai, X_test_openai, y_test_openai_enc)\n",
        "\n",
        "\n",
        "mlpopenai  = MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500, random_state=42)\n",
        "mlpopenai .fit(X_train_openai,y_train_openai_enc)\n",
        "accuracy(\"MLPClassifier\", mlpopenai , X_test_openai, y_test_openai_enc)\n",
        "\n",
        "\n",
        "xgbopenai = XGBClassifier(n_estimators=300, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgbopenai.fit(X_train_openai,y_train_openai_enc)\n",
        "accuracy(\"XGBClassifier\", xgbopenai, X_test_openai, y_test_openai_enc)\n",
        "\n",
        "\n",
        "lgbmopenai = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.05, max_depth=7, random_state=42)\n",
        "lgbmopenai.fit(X_train_openai,y_train_openai_enc)\n",
        "accuracy(\"LGBMClassifier\", lgbmopenai, X_test_openai, y_test_openai_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0q6cYshLEs6"
      },
      "outputs": [],
      "source": [
        "def accuracy_alltogether(names,models,X_test,y_test):\n",
        "\n",
        "  for name, model in zip(names, models):\n",
        "    y_pred = cl.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Precision\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Recall\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # F1-score\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"{name:30} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh_IjcS0MMc1"
      },
      "outputs": [],
      "source": [
        "print(f\"{'Model':30} {'Accuracy':10} {'Precision':10} {'Recall':10} {'F1-score':10}\")\n",
        "print(\"-\" * 80)\n",
        "names = [\"LogisticRegression-TFIDF\", \"LinearSVC-TFIDF\", \"RandomForestClassifier-TFIDF\"]\n",
        "models = [cl, svm, rf]\n",
        "\n",
        "accuracy_alltogether(names,models,X_test,y_test)\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "names = [\"LogisticRegression-BGE\", \"LinearSVC-BGE\", \"RandomForestClassifier-BGE\", \"KNeighborsClassifier-BGE\", \"MLPClassifier-BGE\", \"XGBClassifier-BGE\",  \"LGBMClassifier-BGE\"]\n",
        "models = [clbge, svmbge, rfbge, knnbge, mlpbge, xgbbge, lgbmbge]\n",
        "\n",
        "accuracy_alltogether(names,models, X_test_bge, y_test_bge_enc)\n",
        "\n",
        "names = [\"LogisticRegression-OpenAI\", \"LinearSVC-OpenAI\", \"RandomForestClassifier-OpenAI\", \"KNeighborsClassifier-OpenAI\", \"MLPClassifier-OpenAI\", \"XGBClassifier-OpenAI\",  \"LGBMClassifier-OpenAI\"]\n",
        "models = [clopenai, svmopenai, rfopenai, knnopenai, mlpopenai, xgbopenai, lgbmopenai]\n",
        "\n",
        "accuracy_alltogether(names,models, X_test_openai, y_test_openai_enc)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}